{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
    "outputId": "7227ac19-97f5-40a0-965c-a7040265b636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 12.2 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 17.5 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 12.1 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 11.9 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.4/116.4 kB 15.5 MB/s eta 0:00:00\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 526.7/526.7 kB 50.1 MB/s eta 0:00:00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip -q install pydicom opencv-python scikit-image pyradiomics\n",
    "\n",
    "wget -q http://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz && tar -xf imagens_ihq.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "NOphUOjaSsq0",
   "metadata": {
    "id": "NOphUOjaSsq0"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "import pydicom as dicom\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import SimpleITK as sitk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364a4a5-2187-415e-83f8-3c6c59912354",
   "metadata": {
    "id": "6364a4a5-2187-415e-83f8-3c6c59912354"
   },
   "outputs": [],
   "source": [
    "def cut_images(input_path, new_width, new_height, output_path=None):\n",
    "    \"\"\"\n",
    "    Cut images into the desired size and save the output images\n",
    "\n",
    "    Params:\n",
    "    input_path: path to the original images\n",
    "    output_path: path to save the cut images\n",
    "    new_width: width of the cut images\n",
    "    new_height: height of the cut images\n",
    "\n",
    "    Return:\n",
    "\n",
    "    images_data: dictionary with images names as keys\n",
    "    and images as values\n",
    "    patients: list of patients IDs\n",
    "    classes = list of labels\n",
    "    \"\"\"\n",
    "    images_data = {}\n",
    "    classes = []\n",
    "    patients = []\n",
    "\n",
    "    n = 0\n",
    "    # Browse input path\n",
    "    for class_dir in os.listdir(input_path):\n",
    "        class_path = os.path.join(input_path, class_dir)\n",
    "\n",
    "        # If it is a directory\n",
    "        if os.path.isdir(class_path):\n",
    "\n",
    "            # Save image id\n",
    "            image_id = 1\n",
    "\n",
    "            # Go through images\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                # Save patient id\n",
    "                patient = image_file.split(\"_\")[0]\n",
    "                patients.append(patient)\n",
    "\n",
    "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # If image exists\n",
    "                if image is not None:\n",
    "\n",
    "                    # Save subimage id\n",
    "                    sub_id = 1\n",
    "\n",
    "                    for i in range(0, image.shape[0], new_height):\n",
    "                        for j in range(0, image.shape[1], new_width):\n",
    "\n",
    "                            # Cut image into subimage\n",
    "                            sub_image = image[i:i+new_height, j:j+new_width]\n",
    "\n",
    "                            # Image name identifier\n",
    "                            image_name = f\"{patient}-img{image_id}-{sub_id}\"\n",
    "\n",
    "                            # Append image and its label to the dictionary\n",
    "                            # if image_name not in images_data:\n",
    "                            #     image_name = f\"{patient}2-img{image_id}-{sub_id}\"\n",
    "                            #     images_data[image_name] = sub_image\n",
    "                            # else:\n",
    "                            images_data[image_name] = sub_image\n",
    "\n",
    "                            classes.append(int(class_dir))\n",
    "\n",
    "                            # Write subimage if an output path was given\n",
    "                            if output_path != None:\n",
    "                                # Create dir if it doesn't exist\n",
    "                                os.makedirs(os.path.join(output_path, class_dir), exist_ok=True)\n",
    "                                # Output file path\n",
    "                                output_file = f\"{image_name}.png\"\n",
    "                                output_file = os.path.join(output_path, class_dir, output_file)\n",
    "                                # Save subimage\n",
    "                                cv.imwrite(output_file, sub_image)\n",
    "\n",
    "                            sub_id += 1\n",
    "                            n += 1\n",
    "\n",
    "                image_id += 1\n",
    "\n",
    "    return images_data, patients, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069",
   "metadata": {
    "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069"
   },
   "outputs": [],
   "source": [
    "def divide_folds(image_names, patients, classes):\n",
    "    \"\"\"\n",
    "    Divides a dataset into folds for stratified k-fold cross-validation.\n",
    "\n",
    "    Params:\n",
    "    images_names: list of all images names\n",
    "    patients: list with patient id for each image\n",
    "    classes: list with class for each image\n",
    "\n",
    "    Return:\n",
    "    folds: list of tuples, each tuple is one fold containing (imgs_names, labels)\n",
    "    \"\"\"\n",
    "    # Create a list of unique indexes for patients\n",
    "    unique_patients = list(set(patients))\n",
    "\n",
    "    # Number of folds\n",
    "    n_folds = 5\n",
    "\n",
    "    patients_per_fold = len(unique_patients)//n_folds\n",
    "    left = [(len(unique_patients)-i) for i in range(1, (len(unique_patients)%n_folds)+1)]\n",
    "\n",
    "    images_classes = dict(zip(images_names, classes))\n",
    "    assigned_patients = []\n",
    "    folds = []\n",
    "\n",
    "    for i in range(n_folds):\n",
    "\n",
    "        n_patients = 0\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        if i == n_folds-1:\n",
    "            for j in left:\n",
    "\n",
    "                patient = patients[-j]\n",
    "\n",
    "                imgs_patient = [name for name in image_names if patient in name]\n",
    "                x = x + imgs_patient\n",
    "                y = y + [images_classes[key] for key in imgs_patient]\n",
    "                n_patients += 1\n",
    "                assigned_patients.append(patient)\n",
    "\n",
    "        for k in range(len(unique_patients)):\n",
    "\n",
    "            patient = unique_patients[k]\n",
    "\n",
    "            if n_patients < patients_per_fold and patient not in assigned_patients:\n",
    "                imgs_patient = [name for name in image_names if patient in name]\n",
    "                x = x + imgs_patient\n",
    "                y = y + [images_classes[key] for key in imgs_patient]\n",
    "                n_patients += 1\n",
    "                assigned_patients.append(patient)\n",
    "\n",
    "        folds.append((x, y))\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbQLaO1PoMcg",
   "metadata": {
    "id": "dbQLaO1PoMcg"
   },
   "outputs": [],
   "source": [
    "def preprocess(images_data):\n",
    "    \"\"\"\n",
    "    Apply normalization, blur and sharpening to the images\n",
    "\n",
    "    Params:\n",
    "    images_data: dictionary with images names as keys\n",
    "    and images as values\n",
    "\n",
    "    Return:\n",
    "    new_data: dictionary with images names as keys\n",
    "    and processed images as values\n",
    "    \"\"\"\n",
    "\n",
    "    new_data = images_data.copy()\n",
    "\n",
    "    for key, value in new_data.items():\n",
    "\n",
    "        img = value\n",
    "\n",
    "        # Normalize between 0 and 1\n",
    "        norm = cv.normalize(img, None, 0, 1.0, cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "\n",
    "        # Gaussian blur\n",
    "        blur = cv.GaussianBlur(norm, (3, 3), 1)\n",
    "\n",
    "        # Sharpen the image\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharp = cv.filter2D(blur, -1, kernel)\n",
    "\n",
    "        new_data[key] = sharp\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721",
   "metadata": {
    "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721"
   },
   "outputs": [],
   "source": [
    "def apply_thresholds(images_data):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    images_data: dictionary with images names as keys\n",
    "    and images as values\n",
    "\n",
    "    Params:\n",
    "    imgs: list of raw images\n",
    "\n",
    "    Return:\n",
    "    new_data: dictionary with images names as keys\n",
    "    and (images, Otsu's, Adaptative) as values\n",
    "    extractor: pyradiomics extractor\n",
    "    \"\"\"\n",
    "\n",
    "    new_data = images_data.copy()\n",
    "\n",
    "    for key, value in new_data.items():\n",
    "\n",
    "        # Otsu's thresholding\n",
    "        _, th1 = cv.threshold(value, 100, 1, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "        # Adaptative gaussian thresholding\n",
    "        #th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n",
    "        th3 = cv.adaptiveThreshold(value, 1, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        new_data[key] = (value, th1, th3)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
   "metadata": {
    "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d"
   },
   "outputs": [],
   "source": [
    "# Cut images into 40x30\n",
    "images_data, patients, classes = cut_images(\"imagens_ihq_er\", 40, 30)\n",
    "\n",
    "# Divide images into folds\n",
    "images_names = list(images_data.keys())\n",
    "folds = divide_folds(images_names, patients, classes)\n",
    "\n",
    "# Save folds variable \n",
    "dump(folds, 'folds.joblib')\n",
    "\n",
    "# Preprocess images_data\n",
    "images_data = preprocess(images_data)\n",
    "\n",
    "# # Update images_data, applying Otsu's and adaptive thresholds\n",
    "images_data = apply_thresholds(images_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec",
   "metadata": {
    "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec"
   },
   "source": [
    "Extract features with PyRadiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45",
   "metadata": {
    "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45"
   },
   "outputs": [],
   "source": [
    "def run_extractor(images_data, extractor):\n",
    "    \"\"\"\n",
    "    Extract features using sitk and pyradiomics\n",
    "\n",
    "    Params:\n",
    "    images_data: dictionary with images names as keys\n",
    "    and (images, Otsu's, Adaptative) as values\n",
    "    extractor: pyradiomics extractor\n",
    "\n",
    "    Returns:\n",
    "    features_otsu: features for otsu mask\n",
    "    features_adapt: features for adaptative mask\n",
    "    \"\"\"\n",
    "\n",
    "    data_spacing=[1,1,1]\n",
    "    features_otsu = {}\n",
    "    features_adapt = {}\n",
    "\n",
    "    for key, value in images_data.items():\n",
    "\n",
    "        # Get raw, Otsu's and adaptive images\n",
    "        img = value[0]\n",
    "        img_otsu = value[1]\n",
    "        img_adapt = value[2]\n",
    "\n",
    "        sitk_img = sitk.GetImageFromArray(img)\n",
    "        sitk_img.SetSpacing((1, 1, 1))\n",
    "        sitk_img = sitk.JoinSeries(sitk_img)\n",
    "\n",
    "        sitk_otsu = sitk.GetImageFromArray(img_otsu)\n",
    "        sitk_otsu.SetSpacing((1, 1, 1))\n",
    "        sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
    "        sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
    "\n",
    "        sitk_adapt = sitk.GetImageFromArray(img_adapt)\n",
    "        sitk_adapt.SetSpacing((1, 1, 1))\n",
    "        sitk_adapt = sitk.JoinSeries(sitk_adapt)\n",
    "        sitk_adapt = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
    "\n",
    "        # Extract features and append them to the proper list\n",
    "        try:\n",
    "            ft_otsu = extractor.execute(sitk_img, sitk_otsu)\n",
    "            features_otsu[key] = ft_otsu\n",
    "\n",
    "            ft_adapt = extractor.execute(sitk_img, sitk_adapt)\n",
    "            features_adapt[key] = ft_adapt\n",
    "\n",
    "        except:\n",
    "            print(f\"{key}, \", end=\"\")\n",
    "            pass\n",
    "\n",
    "    return features_otsu, features_adapt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f005e-92be-49b2-b869-f622389d0a68",
   "metadata": {
    "id": "283f005e-92be-49b2-b869-f622389d0a68"
   },
   "outputs": [],
   "source": [
    "def conditional_append(element, dest):\n",
    "    \"\"\"\n",
    "    Append element to the list destiny, if element is not in destiny\n",
    "\n",
    "    Params:\n",
    "    element: an element of any kind\n",
    "    dest: a destination list\n",
    "\n",
    "    Returns:\n",
    "    dest: list with appended element if the element was not in there\n",
    "    \"\"\"\n",
    "    if element not in dest:\n",
    "        dest.append(element)\n",
    "\n",
    "    return dest\n",
    "\n",
    "def process_features(feats_o, feats_a):\n",
    "    \"\"\"\n",
    "    Process features, in a way that:\n",
    "    - features that are dictionaries and strings are removed\n",
    "    - features that are tuples are separated and each element\n",
    "    of the tuple is considered one feature\n",
    "    - other types are converted to float\n",
    "\n",
    "    Params:\n",
    "    feats_o: list of Otsu's threshold features\n",
    "    feats_a: list of adaptativa threshold features\n",
    "\n",
    "    Returns:\n",
    "    all_feats_o: Otsu's features processed\n",
    "    all_feats_a: adaptative features processed\n",
    "    names = feature names processed\n",
    "    \"\"\"\n",
    "\n",
    "    all_feats_o = {}\n",
    "    all_feats_a = {}\n",
    "    names = []\n",
    "\n",
    "    # For each image in one of the features list\n",
    "    for key in feats_o:\n",
    "\n",
    "        # Get features for Otsu's and adaptive for this sample\n",
    "        sample_o = feats_o[key]\n",
    "        sample_a = feats_a[key]\n",
    "\n",
    "        values_o = []\n",
    "        values_a = []\n",
    "\n",
    "        # For each feature in the list\n",
    "        for ft in sample_o:\n",
    "\n",
    "            # Get the feature's value\n",
    "            value_o = sample_o[ft]\n",
    "            value_a = sample_a[ft]\n",
    "\n",
    "            # If the value is str or dict, ignore it\n",
    "            if type(value_o) == str or type(value_o) == dict:\n",
    "                continue\n",
    "            # If it's a tuple\n",
    "            elif type(value_o) == tuple:\n",
    "                for e in range(len(value_o)):\n",
    "                    # Add and index to the feature name\n",
    "                    conditional_append(f'{ft}_{e}', names)\n",
    "                    # Append float values to the lists\n",
    "                    values_o.append(float(value_o[e]))\n",
    "                    values_a.append(float(value_a[e]))\n",
    "            # For other data types, just append the name and float values\n",
    "            else:\n",
    "                conditional_append(ft, names)\n",
    "                values_o.append(float(value_o))\n",
    "                values_a.append(float(value_a))\n",
    "\n",
    "        # Append processed features to the general list\n",
    "        all_feats_o[key] = values_o\n",
    "        all_feats_a[key] = values_a\n",
    "\n",
    "    return all_feats_o, all_feats_a, names\n",
    "\n",
    "def extract_features(images_data):\n",
    "    \"\"\"\n",
    "    Process features, in a way that:\n",
    "    - features that are dictionaries and strings are removed\n",
    "    - features that are tuples are separated and each element\n",
    "    of the tuple is considered one feature\n",
    "    - other types are converted to float\n",
    "    Get the features' names, with tuple features indexed\n",
    "\n",
    "    Params:\n",
    "    images_data: dictionary with images names as keys\n",
    "    and (images, Otsu's, Adaptative) as values\n",
    "\n",
    "    Returns:\n",
    "    all_folds_feats: dictionary containing Otsu's features\n",
    "    and adaptive features for each fold\n",
    "    names: feature names\n",
    "    \"\"\"\n",
    "\n",
    "    # Create feature extractor\n",
    "    !wget -c https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
    "    params = 'Params.yaml'\n",
    "    settings = {'label': 1, 'correctMask': True}\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True, **settings)\n",
    "\n",
    "    # Extract features from Otsu's and adaptative\n",
    "    feats_o, feats_a = run_extractor(images_data, extractor)\n",
    "\n",
    "    # Process features and get feature names\n",
    "    all_feats_o, all_feats_a, names = process_features(feats_o, feats_a)\n",
    "\n",
    "    return all_feats_o, all_feats_a, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e61d82-9315-4171-93fd-1bdbe27b17bf",
   "metadata": {
    "id": "b0e61d82-9315-4171-93fd-1bdbe27b17bf"
   },
   "outputs": [],
   "source": [
    "# Division of images_data dictionary in 4 parts\n",
    "# to extract features easily\n",
    "\n",
    "# lista = list(images_data.keys())\n",
    "# p = lista[:10000]\n",
    "# s = lista[10000:20000]\n",
    "# t = lista[20000:30000]\n",
    "# q = lista[30000:40000]\n",
    "\n",
    "# pp = {k:images_data[k] for k in p}\n",
    "# ss = {k:images_data[k] for k in s}\n",
    "# tt = {k:images_data[k] for k in t}\n",
    "# qq = {k:images_data[k] for k in q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20992f0-183f-4cff-b718-67608f9100ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c20992f0-183f-4cff-b718-67608f9100ff",
    "outputId": "d35978d6-b274-4a7a-f90f-7f88fa7a49cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-26 23:10:38--  https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:radiomics.featureextractor:Loading parameter file Params.yaml\n",
      "INFO:radiomics.featureextractor:Applying custom setting overrides: {'additionalInfo': True, 'label': 1, 'correctMask': True}\n",
      "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
      "INFO:radiomics.featureextractor:Loading image and mask\n",
      "INFO:radiomics.featureextractor:Computing shape\n",
      "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
      "INFO:radiomics.featureextractor:Calculating features for original image\n",
      "INFO:radiomics.featureextractor:Computing firstorder\n",
      "INFO:radiomics.featureextractor:Computing glcm\n",
      "INFO:radiomics.featureextractor:Computing glrlm\n",
      "INFO:radiomics.featureextractor:Computing glszm\n",
      "INFO:radiomics.featureextractor:Computing gldm\n",
      "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
      "INFO:radiomics.featureextractor:Loading image and mask\n",
      "INFO:radiomics.featureextractor:Computing shape\n",
      "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
      "INFO:radiomics.featureextractor:Calculating features for original image\n",
      "INFO:radiomics.featureextractor:Computing firstorder\n",
      "INFO:radiomics.featureextractor:Computing glcm\n",
      "INFO:radiomics.featureextractor:Computing glrlm\n",
      "INFO:radiomics.featureextractor:Computing glszm\n",
      "INFO:radiomics.featureextractor:Computing gldm\n",
      "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
      "INFO:radiomics.featureextractor:Loading image and mask\n",
      "INFO:radiomics.featureextractor:Computing shape\n",
      "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
      "INFO:radiomics.featureextractor:Calculating features for original image\n",
      "INFO:radiomics.featureextractor:Computing firstorder\n",
      "INFO:radiomics.featureextractor:Computing glcm\n",
      "INFO:radiomics.featureextractor:Computing glrlm\n",
      "INFO:radiomics.featureextractor:Computing glszm\n",
      "INFO:radiomics.featureextractor:Computing gldm\n",
      "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
      "INFO:radiomics.featureextractor:Loading image and mask\n",
      "INFO:radiomics.featureextractor:Computing shape\n",
      "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
      "INFO:radiomics.featureextractor:Calculating features for original image\n",
      "INFO:radiomics.featureextractor:Computing firstorder\n",
      "INFO:radiomics.featureextractor:Computing glcm\n",
      "INFO:radiomics.featureextractor:Computing glrlm\n",
      "INFO:radiomics.featureextractor:Computing glszm\n",
      "INFO:radiomics.featureextractor:Computing gldm\n"
     ]
    }
   ],
   "source": [
    "# Extract all features\n",
    "all_feats_o, all_feats_a, ft_names = extract_features(images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I3VzTAqtkwpw",
   "metadata": {
    "id": "I3VzTAqtkwpw"
   },
   "outputs": [],
   "source": [
    "def save_features(all_feats_o, all_feats_a):\n",
    "    \"\"\"\n",
    "    Save features of all images in .txt files\n",
    "\n",
    "    Params:\n",
    "    all_feats_o:\n",
    "\n",
    "    Returns:\n",
    "    all_folds_feats = dictionary containing Otsu's features\n",
    "    and adaptive features for each fold\n",
    "    names = feature names\n",
    "    \"\"\"\n",
    "\n",
    "    out_o = 'features_o/'\n",
    "    out_a = 'features_a/'\n",
    "\n",
    "    os.makedirs(out_o, exist_ok=True)\n",
    "    os.makedirs(out_a, exist_ok=True)\n",
    "\n",
    "    for key in all_feats_o:\n",
    "\n",
    "        ft_o = all_feats_o[key]\n",
    "        ft_a = all_feats_a[key]\n",
    "\n",
    "        filename_o = f'{key}_o.txt'\n",
    "        filename_a = f'{key}_a.txt'\n",
    "\n",
    "        with open(os.path.join(out_o, filename_o), 'w') as f:\n",
    "            for elem in ft_o:\n",
    "                f.write(f'{elem}\\n')\n",
    "\n",
    "        with open(os.path.join(out_a, filename_a), 'w') as f:\n",
    "            for elem in ft_a:\n",
    "                f.write(f'{elem}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2tsatBXxmRjl",
   "metadata": {
    "id": "2tsatBXxmRjl"
   },
   "outputs": [],
   "source": [
    "# Save features and feature_names\n",
    "save_features(all_feats_o, all_feats_a)\n",
    "with open('ft_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(ft_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40d964-b6dd-4b05-9c09-4bf3332f5925",
   "metadata": {
    "id": "8a40d964-b6dd-4b05-9c09-4bf3332f5925"
   },
   "outputs": [],
   "source": [
    "# Download features if in Google Colab\n",
    "# !zip -r /content/features_o.zip /content/features_o\n",
    "# !zip -r /content/features_a.zip /content/features_a\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download(\"/content/features_o.zip\")\n",
    "# files.download(\"/content/features_a.zip\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
