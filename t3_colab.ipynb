{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
      "metadata": {
        "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pip install pydicom opencv-python scikit-image\n",
        "# pip install pyradiomics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --show-progress http://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPo6GUbncUox",
        "outputId": "dd6538d1-fd7c-4f30-d058-c05ed68bc261"
      },
      "id": "QPo6GUbncUox",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-16 19:49:33--  http://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz\n",
            "Resolving www.inf.ufpr.br (www.inf.ufpr.br)... 200.17.202.113, 2801:82:80ff:8001:216:ccff:feaa:79\n",
            "Connecting to www.inf.ufpr.br (www.inf.ufpr.br)|200.17.202.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz [following]\n",
            "--2023-11-16 19:49:34--  https://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz\n",
            "Connecting to www.inf.ufpr.br (www.inf.ufpr.br)|200.17.202.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 74889388 (71M) [application/octet-stream]\n",
            "Saving to: ‘imagens_ihq.tar.gz’\n",
            "\n",
            "imagens_ihq.tar.gz  100%[===================>]  71.42M  16.3MB/s    in 5.4s    \n",
            "\n",
            "2023-11-16 19:49:40 (13.3 MB/s) - ‘imagens_ihq.tar.gz’ saved [74889388/74889388]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3d96161f-6336-49be-ae1a-5f50cbdf5e31",
      "metadata": {
        "id": "3d96161f-6336-49be-ae1a-5f50cbdf5e31"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "import pydicom as dicom\n",
        "import radiomics\n",
        "from radiomics import featureextractor\n",
        "import SimpleITK as sitk\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6364a4a5-2187-415e-83f8-3c6c59912354",
      "metadata": {
        "id": "6364a4a5-2187-415e-83f8-3c6c59912354"
      },
      "outputs": [],
      "source": [
        "def cut_images(input_path, output_path, new_width, new_height):\n",
        "    \"\"\"\n",
        "    Cut images into the desired size and save the output images\n",
        "\n",
        "    Params:\n",
        "    input_path = path to the original images\n",
        "    output_path = path to save the cut images\n",
        "    new_width = width of the cut images\n",
        "    new_height = height of the cut images\n",
        "\n",
        "    Return:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    # Create dir if it doesn't exist\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    n_images = 0\n",
        "\n",
        "    # Browse input path\n",
        "    for class_dir in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "\n",
        "        # If it is a directory\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            # Save image id\n",
        "            image_id = 1\n",
        "\n",
        "            # Go through images\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                # Save patient id\n",
        "                patient = image_file.split(\"_\")[0]\n",
        "\n",
        "                image = cv.imread(image_path)\n",
        "\n",
        "                # If image exists\n",
        "                if image is not None:\n",
        "\n",
        "                    # Save subimage id\n",
        "                    sub_id = 1\n",
        "\n",
        "                    for i in range(0, image.shape[0], new_height):\n",
        "                        for j in range(0, image.shape[1], new_width):\n",
        "\n",
        "                            # Cut image into subimage\n",
        "                            sub_image = image[i:i+new_height, j:j+new_width]\n",
        "\n",
        "                            # Output file path\n",
        "                            output_file = f\"{patient}_img{image_id}-{sub_id}.png\"\n",
        "                            output_file = os.path.join(output_path, class_dir, output_file)\n",
        "\n",
        "                            # Save subimage\n",
        "                            cv.imwrite(output_file, sub_image)\n",
        "\n",
        "                            sub_id += 1\n",
        "                            n_images += 1\n",
        "\n",
        "                    image_id += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images_colab(input_path):\n",
        "    \"\"\"\n",
        "    Read images in the input_path,\n",
        "    save image, patient of each image and the class (group/labels)\n",
        "\n",
        "    Params:\n",
        "    input_path = path to the original images\n",
        "\n",
        "    Return:\n",
        "    images = list of all images\n",
        "    patients = list with patient id for each image\n",
        "    classes = list with class for each image\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to save images, patients and classes\n",
        "    images = []\n",
        "    patients = []\n",
        "    classes = []\n",
        "\n",
        "    # Browse input path\n",
        "    for class_dir in glob.glob(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "        print(class_dir)\n",
        "    #     # If it is a directory\n",
        "    #     if os.path.isdir(class_path):\n",
        "\n",
        "    #         for image_file in os.listdir(class_path):\n",
        "    #             image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "    #             patient = image_file.split(\"_\")[0]\n",
        "\n",
        "    #             image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "    #             # Append image, patient id and class to list\n",
        "    #             images.append(image)\n",
        "    #             patients.append(patient)\n",
        "    #             classes.append(class_dir)\n",
        "\n",
        "    # return (images, patients, classes)"
      ],
      "metadata": {
        "id": "kdCtyo2BdxnT"
      },
      "id": "kdCtyo2BdxnT",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "54a4d795-c9a9-49b4-8f07-2f43233fa24c",
      "metadata": {
        "id": "54a4d795-c9a9-49b4-8f07-2f43233fa24c"
      },
      "outputs": [],
      "source": [
        "def read_images(input_path):\n",
        "    \"\"\"\n",
        "    Read images in the input_path,\n",
        "    save image, patient of each image and the class (group/labels)\n",
        "\n",
        "    Params:\n",
        "    input_path = path to the original images\n",
        "\n",
        "    Return:\n",
        "    images = list of all images\n",
        "    patients = list with patient id for each image\n",
        "    classes = list with class for each image\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to save images, patients and classes\n",
        "    images = []\n",
        "    patients = []\n",
        "    classes = []\n",
        "\n",
        "    # Browse input path\n",
        "    for class_dir in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "\n",
        "        # If it is a directory\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                patient = image_file.split(\"_\")[0]\n",
        "\n",
        "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Append image, patient id and class to list\n",
        "                images.append(image)\n",
        "                patients.append(patient)\n",
        "                classes.append(class_dir)\n",
        "\n",
        "    return (images, patients, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069",
      "metadata": {
        "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069"
      },
      "outputs": [],
      "source": [
        "def divide_folds(images, patients, classes):\n",
        "    \"\"\"\n",
        "    Divides a dataset into folds for stratified k-fold cross-validation.\n",
        "\n",
        "    Params:\n",
        "    images = list of all images\n",
        "    patients = list with patient id for each image\n",
        "    classes = list with class for each image\n",
        "\n",
        "    Return:\n",
        "    folds = list of tuples, each tuple is one folder\n",
        "    \"\"\"\n",
        "    # Create a list of unique indexes for patients\n",
        "    unique_patients = list(set(patients))\n",
        "\n",
        "    # Shuffle the list of unique indexes\n",
        "    random.shuffle(unique_patients)\n",
        "\n",
        "    # Divide patients into groups\n",
        "    n_folds = 4 # since it's not an exact division, there will be 5 folds\n",
        "    fold_size = len(unique_patients) // n_folds\n",
        "    patients_folds = [unique_patients[i:i+fold_size] for i in range(0, len(unique_patients), fold_size)]\n",
        "\n",
        "    # List to save folds\n",
        "    folds = []\n",
        "\n",
        "    # Divide images into folds based on patients\n",
        "    for i, patients_folds in enumerate(patients_folds):\n",
        "        train_patients = [p for p in unique_patients if p not in patients_folds]\n",
        "        test_patients = patients_folds\n",
        "\n",
        "        train_indices = [i for i, patient in enumerate(patients) if patient in train_patients]\n",
        "        test_indices = [i for i, patient in enumerate(patients) if patient in test_patients]\n",
        "\n",
        "        train_images = [images[i] for i in train_indices]\n",
        "        test_images = [images[i] for i in test_indices]\n",
        "        train_classes = [classes[i] for i in train_indices]\n",
        "        test_classes = [classes[i] for i in test_indices]\n",
        "\n",
        "        folds.append((train_images, test_images, train_classes, test_classes))\n",
        "\n",
        "    return folds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721",
      "metadata": {
        "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721"
      },
      "outputs": [],
      "source": [
        "def apply_thresholds(imgs):\n",
        "    \"\"\"\n",
        "    Apply Otsu's and Adaptative thresholds to images\n",
        "\n",
        "    Params:\n",
        "    imgs = list of raw images\n",
        "\n",
        "    Return:\n",
        "    imgs_otsu = Otsu's thresholded images\n",
        "    imgs_adapt = Adaptative thresholded images\n",
        "    \"\"\"\n",
        "\n",
        "    imgs_otsu = []\n",
        "    imgs_adapt = []\n",
        "\n",
        "    # For each image in dataset\n",
        "    for img in imgs:\n",
        "\n",
        "        # Otsu's thresholding\n",
        "        _, th1 = cv.threshold(img, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "        # Adaptative gaussian thresholding\n",
        "        #th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n",
        "        th3 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,11,2)\n",
        "\n",
        "        imgs_otsu.append(th1)\n",
        "        imgs_adapt.append(th3)\n",
        "\n",
        "    return (imgs_otsu, imgs_adapt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ca7cfa20-c693-47ef-acfc-3a17fa27ef33",
      "metadata": {
        "id": "ca7cfa20-c693-47ef-acfc-3a17fa27ef33"
      },
      "outputs": [],
      "source": [
        "def update_folds(folds):\n",
        "    \"\"\"\n",
        "    For each fold, add Otsu's and adaptive\n",
        "    thresholding of all test and train images\n",
        "\n",
        "    Params:\n",
        "    folds = list of tuples containing the images divided in folds\n",
        "\n",
        "    Returns:\n",
        "    new_folds = updated list of tuples containing the images and masks divided in folds\n",
        "    \"\"\"\n",
        "\n",
        "    # For each fold\n",
        "    for i in range(len(folds)):\n",
        "        fold = folds[i]\n",
        "        new_folds = []\n",
        "\n",
        "        x_train = fold[0]\n",
        "        x_test = fold[1]\n",
        "        y_train = fold[2]\n",
        "        y_test = fold[3]\n",
        "\n",
        "        x_train_otsu, x_train_adapt = apply_thresholds(x_train)\n",
        "        x_test_otsu, x_test_adapt = apply_thresholds(x_test)\n",
        "\n",
        "        # Update list with the thresholds\n",
        "        new_folds[i] = (x_train, x_train_otsu, x_train_adapt, x_test, x_test_otsu, x_test_adapt, y_train, y_test)\n",
        "\n",
        "    return new_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
        "outputId": "fbc6a482-0a2a-4fe2-b46a-ff2a85a1f6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/imagens_cortadas\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4acaf59bb0ba>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save images, patients and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/imagens_cortadas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Divide images into folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "# Cut images into 40x30\n",
        "#cut_images(\"imagens_ihq_er\", \"imagens_cortadas\", 40, 30)\n",
        "\n",
        "# Save images, patients and classes\n",
        "images, patients, classes = read_images_colab(\"/content/imagens_cortadas\")\n",
        "\n",
        "# Divide images into folds\n",
        "folds = divide_folds(images, patients, classes)\n",
        "\n",
        "# Save folds\n",
        "dump(folds, '../folds.joblib')\n",
        "\n",
        "# Load folds\n",
        "# folds = load('../folds.joblib')\n",
        "\n",
        "# Apply Otsu's and adaptive thresholds\n",
        "folds = update_folds(folds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec",
      "metadata": {
        "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec"
      },
      "source": [
        "Extract features with PyRadiomics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd36fb7d-2ffb-4f1b-9290-945925e2800a",
      "metadata": {
        "id": "fd36fb7d-2ffb-4f1b-9290-945925e2800a"
      },
      "outputs": [],
      "source": [
        "# Create feature extractor\n",
        "# !wget -c https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
        "params = 'Params.yaml'\n",
        "settings = {'label': 255}\n",
        "extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45",
      "metadata": {
        "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45"
      },
      "outputs": [],
      "source": [
        "# Extract features using sitk and pyradiomics\n",
        "# Input:\n",
        "# imgs = raw images\n",
        "# otsu = masked images with otsu thresholding\n",
        "# adapt = masked images with adaptative thresholding\n",
        "# extractor = pyradiomics extractor\n",
        "# Output:\n",
        "# features_otsu = features for otsu mask\n",
        "# features_adapt = features for adaptative mask\n",
        "def extract_features(imgs, otsu, adapt, extractor):\n",
        "\n",
        "    for idx in range(len(data)):\n",
        "\n",
        "        train_img = imgs[idx]\n",
        "        train_otsu = otsu[idx]\n",
        "        train_adapt = adapt[idx]\n",
        "\n",
        "        sitk_img = sitk.GetImageFromArray(train_img)\n",
        "        sitk_img.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
        "        sitk_img = sitk.JoinSeries(sitk_img)\n",
        "\n",
        "        sitk_otsu = sitk.GetImageFromArray(train_otsu)\n",
        "        sitk_otsu.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
        "        sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
        "        sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        sitk_adapt = sitk.GetImageFromArray(train_adapt)\n",
        "        sitk_adapt.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
        "        sitk_adapt = sitk.JoinSeries(sitk_adapt)\n",
        "        sitk_adapt = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        features_otsu = extractor.execute(sitk_img, sitk_otsu)\n",
        "        features_adapt = extractor.execute(sitk_img, sitk_adapt)\n",
        "\n",
        "        return (features_otsu, features_adapt)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f691b44-c759-4cc7-ad31-512f902466af",
      "metadata": {
        "id": "9f691b44-c759-4cc7-ad31-512f902466af",
        "outputId": "b90daa69-e744-4c04-e213-ad1e4eb76178"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2827833846.py, line 29)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_7165/2827833846.py\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    for idx in range(len(x_test)):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Extract features\n",
        "\n",
        "data_spacing=[1,1,1]\n",
        "features_otsu = {}\n",
        "features_adapt = {}\n",
        "\n",
        "# For each fold\n",
        "for i in range(len(folds)):\n",
        "\n",
        "    fold = folds[i]\n",
        "\n",
        "    x_train = fold[0]\n",
        "    x_train_otsu = fold[1]\n",
        "    x_train_adapt = fold[2]\n",
        "    x_test = fold[3]\n",
        "    x_test_otsu = fold[4]\n",
        "    x_test_adapt = fold[5]\n",
        "    y_train = fold[6]\n",
        "    y_test = fold[7]\n",
        "\n",
        "    # # Create dataframe to save features\n",
        "    # df_train_otsu = pd.DataFrame()\n",
        "    # df_test_otsu = pd.DataFrame()\n",
        "    # df_train_adapt = pd.DataFrame()\n",
        "    # df_test_adapt = pd.DataFrame()\n",
        "\n",
        "    # Extract features\n",
        "    feats_train_otsu, feats_train_adapt = extract_features(x_train, x_train_otsu, x_train_adapt, extractor)\n",
        "    feats_test_otsu, feats_test_adapt = extract_features(x_test, x_test_otsu, x_test_adapt, extractor)\n",
        "\n",
        "    # Filter features and fix data types\n",
        "\n",
        "    ## em construção\n",
        "\n",
        "#     features_otsu_filtered = []\n",
        "#     features_adapt_filtered = []\n",
        "#     names = list(features_otsu.keys())\n",
        "\n",
        "#     for j in range(len(features_otsu)):\n",
        "#         fo = features_otsu[j]\n",
        "#         fa = features_adapt[j]\n",
        "\n",
        "#         if type(fo) == np.ndarray:\n",
        "#             fo = float(fo)\n",
        "#         else if type(fo) == dict:\n",
        "#             fo = NA\n",
        "#         else if type(fo) == tuple:\n",
        "#             indexes = []\n",
        "#             for e in range(len(fo)):\n",
        "#                 indexes.append(e)\n",
        "#                 fo[e] = float(fo[e])\n",
        "\n",
        "\n",
        "#     df_train_otsu.columns = names\n",
        "#     df_test_adapt.columns = names\n",
        "#     df_train_otsu.columns = names\n",
        "#     df_test_adapt.columns = names\n",
        "\n",
        "    fold_id = i+1\n",
        "    features_dict[fold_id] = (df_train_otsu, df_test_otsu, df_train_adapt, df_test_adapt, y_train, y_test)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3451dcde-2b74-4ac2-b577-d0b52675991e",
      "metadata": {
        "id": "3451dcde-2b74-4ac2-b577-d0b52675991e"
      },
      "source": [
        "Testando pra ver como pegar as features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fded5ae1-bffb-426c-9fe5-0bc5039f02df",
      "metadata": {
        "id": "fded5ae1-bffb-426c-9fe5-0bc5039f02df"
      },
      "outputs": [],
      "source": [
        "# fold 1, 0 = imagens, 1 = segundo\n",
        "test_img = folds[1][0][1]\n",
        "# fold 1, 1 = imagens com otsu, 1 = segundo elemento\n",
        "otsu = folds[1][1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb6fb6d-23f3-4f0b-aaa2-9125087ee1dd",
      "metadata": {
        "id": "4bb6fb6d-23f3-4f0b-aaa2-9125087ee1dd"
      },
      "outputs": [],
      "source": [
        "data_spacing=[1,1,1]\n",
        "sitk_img = sitk.GetImageFromArray(test_img)\n",
        "sitk_img.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
        "sitk_img = sitk.JoinSeries(sitk_img)\n",
        "\n",
        "sitk_mask = sitk.GetImageFromArray(otsu)\n",
        "sitk_mask.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
        "sitk_mask = sitk.JoinSeries(sitk_mask)\n",
        "sitk_mask = sitk.Cast(sitk_mask, sitk.sitkInt32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a5e900-ee50-4142-9dd3-808e48b4d88f",
      "metadata": {
        "id": "55a5e900-ee50-4142-9dd3-808e48b4d88f"
      },
      "outputs": [],
      "source": [
        "features = extractor.execute(sitk_img, sitk_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed66797-7412-497b-93e1-2b484fffb6e7",
      "metadata": {
        "id": "eed66797-7412-497b-93e1-2b484fffb6e7",
        "outputId": "1312be1f-92ae-47e2-fa69-318c13ce560a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2adb7914-fbc3-4390-b261-23e3b37ff8e5",
      "metadata": {
        "id": "2adb7914-fbc3-4390-b261-23e3b37ff8e5",
        "outputId": "05ac6453-4082-4dbe-a57e-f8dbc2724fbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.021795298681438015"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float(list(features.values())[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36c2921-08e9-4b82-a1f3-1dab7db0d261",
      "metadata": {
        "id": "f36c2921-08e9-4b82-a1f3-1dab7db0d261",
        "outputId": "e07070ab-f1c1-4edb-abe8-3ac4669c6ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "for i in list(features.values()):\n",
        "    print(type(i) == str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8e78e4-300e-4e2a-9c76-e93f459a2df9",
      "metadata": {
        "id": "ec8e78e4-300e-4e2a-9c76-e93f459a2df9",
        "outputId": "654002ee-0b00-48f2-c358-d0797decc33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diagnostics_Versions_PyRadiomics v3.1.0\n",
            "diagnostics_Versions_Numpy 1.24.3\n",
            "diagnostics_Versions_SimpleITK 2.3.0\n",
            "diagnostics_Versions_PyWavelet 1.3.0\n",
            "diagnostics_Versions_Python 3.9.13\n",
            "diagnostics_Configuration_Settings {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 255, 'additionalInfo': True, 'binWidth': 25, 'weightingNorm': None}\n",
            "diagnostics_Configuration_EnabledImageTypes {'Original': {}}\n",
            "diagnostics_Image-original_Hash ae37fbfe4969d0864fb25c3fecab05ec1787adac\n",
            "diagnostics_Image-original_Dimensionality 3D\n",
            "diagnostics_Image-original_Spacing (1.0, 1.0, 1.0)\n",
            "diagnostics_Image-original_Size (40, 30, 1)\n",
            "diagnostics_Image-original_Mean 182.48333333333332\n",
            "diagnostics_Image-original_Minimum 74.0\n",
            "diagnostics_Image-original_Maximum 255.0\n",
            "diagnostics_Mask-original_Hash 655cfb8d0ad15a412d717bc98f922ee2ec6f04ee\n",
            "diagnostics_Mask-original_Spacing (1.0, 1.0, 1.0)\n",
            "diagnostics_Mask-original_Size (40, 30, 1)\n",
            "diagnostics_Mask-original_BoundingBox (0, 0, 0, 40, 30, 1)\n",
            "diagnostics_Mask-original_VoxelNum 638\n",
            "diagnostics_Mask-original_VolumeNum 3\n",
            "diagnostics_Mask-original_CenterOfMassIndex (26.954545454545453, 16.387147335423197, 0.0)\n",
            "diagnostics_Mask-original_CenterOfMass (26.954545454545453, 16.387147335423197, 0.0)\n",
            "original_shape_Elongation 0.7094650213812403\n",
            "original_shape_Flatness 0.0\n",
            "original_shape_LeastAxisLength 0.0\n",
            "original_shape_MajorAxisLength 41.29884141070391\n",
            "original_shape_Maximum2DDiameterColumn 40.0\n",
            "original_shape_Maximum2DDiameterRow 30.0\n",
            "original_shape_Maximum2DDiameterSlice 49.4064773081425\n",
            "original_shape_Maximum3DDiameter 49.4064773081425\n",
            "original_shape_MeshVolume 601.6666666666666\n",
            "original_shape_MinorAxisLength 29.300083404465504\n",
            "original_shape_Sphericity 0.2570842831673996\n",
            "original_shape_SurfaceArea 1340.6412107135714\n",
            "original_shape_SurfaceVolumeRatio 2.228212538582113\n",
            "original_shape_VoxelVolume 638.0\n",
            "original_firstorder_10Percentile 220.7\n",
            "original_firstorder_90Percentile 254.0\n",
            "original_firstorder_Energy 37509863.0\n",
            "original_firstorder_Entropy 1.5104876972356283\n",
            "original_firstorder_InterquartileRange 13.0\n",
            "original_firstorder_Kurtosis 7.136994352541768\n",
            "original_firstorder_Maximum 255.0\n",
            "original_firstorder_MeanAbsoluteDeviation 11.138442035750435\n",
            "original_firstorder_Mean 241.9294670846395\n",
            "original_firstorder_Median 247.0\n",
            "original_firstorder_Minimum 179.0\n",
            "original_firstorder_Range 76.0\n",
            "original_firstorder_RobustMeanAbsoluteDeviation 5.92901785714286\n",
            "original_firstorder_RootMeanSquared 242.47244939319094\n",
            "original_firstorder_Skewness -2.1257070236433657\n",
            "original_firstorder_TotalEnergy 37509863.0\n",
            "original_firstorder_Uniformity 0.4007134363852557\n",
            "original_firstorder_Variance 263.0216708758758\n",
            "original_glcm_Autocorrelation 11.430252556805964\n",
            "original_glcm_JointAverage 3.3287935814572673\n",
            "original_glcm_ClusterProminence 11.272758117426303\n",
            "original_glcm_ClusterShade -1.9415682045830591\n",
            "original_glcm_ClusterTendency 1.6541689077316268\n",
            "original_glcm_Contrast 0.2583333002801104\n",
            "original_glcm_Correlation 0.7270977788480786\n",
            "original_glcm_DifferenceAverage 0.22434486772517698\n",
            "original_glcm_DifferenceEntropy 0.8187293902250552\n",
            "original_glcm_DifferenceVariance 0.20755424694718724\n",
            "original_glcm_JointEnergy 0.3051178091884267\n",
            "original_glcm_JointEntropy 2.2148220680567547\n",
            "original_glcm_Imc1 -0.39429007513100667\n",
            "original_glcm_Imc2 0.8116556419012224\n",
            "original_glcm_Idm 0.891226409392905\n",
            "original_glcm_Idmn 0.985432080726089\n",
            "original_glcm_Id 0.89338069775371\n",
            "original_glcm_Idn 0.956251219104755\n",
            "original_glcm_InverseVariance 0.19565905669992772\n",
            "original_glcm_MaximumProbability 0.40143484562614007\n",
            "original_glcm_SumEntropy 1.9471325444081624\n",
            "original_glcm_SumSquares 0.4781255520029343\n",
            "original_glrlm_GrayLevelNonUniformity 52.43335882166189\n",
            "original_glrlm_GrayLevelNonUniformityNormalized 0.29399292863171045\n",
            "original_glrlm_GrayLevelVariance 0.9518946014963084\n",
            "original_glrlm_HighGrayLevelRunEmphasis 8.625139428930522\n",
            "original_glrlm_LongRunEmphasis 28.05546783970255\n",
            "original_glrlm_LongRunHighGrayLevelEmphasis 355.70876737133915\n",
            "original_glrlm_LongRunLowGrayLevelEmphasis 2.7111987498274863\n",
            "original_glrlm_LowGrayLevelRunEmphasis 0.25336232937548275\n",
            "original_glrlm_RunEntropy 4.197789343816262\n",
            "original_glrlm_RunLengthNonUniformity 44.7022698522577\n",
            "original_glrlm_RunLengthNonUniformityNormalized 0.24938248991746137\n",
            "original_glrlm_RunPercentage 0.27860501567398116\n",
            "original_glrlm_RunVariance 14.775792734995814\n",
            "original_glrlm_ShortRunEmphasis 0.5076331452072009\n",
            "original_glrlm_ShortRunHighGrayLevelEmphasis 3.255765890817306\n",
            "original_glrlm_ShortRunLowGrayLevelEmphasis 0.19034162497023854\n",
            "original_glszm_GrayLevelNonUniformity 10.636363636363637\n",
            "original_glszm_GrayLevelNonUniformityNormalized 0.32231404958677684\n",
            "original_glszm_GrayLevelVariance 1.0266299357208448\n",
            "original_glszm_HighGrayLevelZoneEmphasis 5.2727272727272725\n",
            "original_glszm_LargeAreaEmphasis 4015.5151515151515\n",
            "original_glszm_LargeAreaHighGrayLevelEmphasis 46797.878787878784\n",
            "original_glszm_LargeAreaLowGrayLevelEmphasis 380.2114898989899\n",
            "original_glszm_LowGrayLevelZoneEmphasis 0.45896464646464646\n",
            "original_glszm_SizeZoneNonUniformity 7.666666666666667\n",
            "original_glszm_SizeZoneNonUniformityNormalized 0.23232323232323232\n",
            "original_glszm_SmallAreaEmphasis 0.46929700542860164\n",
            "original_glszm_SmallAreaHighGrayLevelEmphasis 1.8702106372197798\n",
            "original_glszm_SmallAreaLowGrayLevelEmphasis 0.2488389591882551\n",
            "original_glszm_ZoneEntropy 3.5220053024636755\n",
            "original_glszm_ZonePercentage 0.05172413793103448\n",
            "original_glszm_ZoneVariance 3641.7373737373737\n",
            "original_gldm_DependenceEntropy 3.8036238627670405\n",
            "original_gldm_DependenceNonUniformity 137.58620689655172\n",
            "original_gldm_DependenceNonUniformityNormalized 0.21565236190682088\n",
            "original_gldm_DependenceVariance 5.681174516759859\n",
            "original_gldm_GrayLevelNonUniformity 255.6551724137931\n",
            "original_gldm_GrayLevelVariance 0.6078163540059551\n",
            "original_gldm_HighGrayLevelEmphasis 11.094043887147336\n",
            "original_gldm_LargeDependenceEmphasis 51.529780564263326\n",
            "original_gldm_LargeDependenceHighGrayLevelEmphasis 632.0595611285266\n",
            "original_gldm_LargeDependenceLowGrayLevelEmphasis 4.909341257401602\n",
            "original_gldm_LowGrayLevelEmphasis 0.14408089515848138\n",
            "original_gldm_SmallDependenceEmphasis 0.05996358953717329\n",
            "original_gldm_SmallDependenceHighGrayLevelEmphasis 0.41509912119671977\n",
            "original_gldm_SmallDependenceLowGrayLevelEmphasis 0.021795298681438015\n"
          ]
        }
      ],
      "source": [
        "for key, val in enumerate(features):\n",
        "    print(val, features[val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9500d076-2196-4557-94c5-a8e0afeb7676",
      "metadata": {
        "id": "9500d076-2196-4557-94c5-a8e0afeb7676"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}