{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
      "metadata": {
        "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
        "outputId": "9695723e-a38a-4cad-8479-3677e3887ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 23.7 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 26.4 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 40.7 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 11.4 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.4/116.4 kB 13.7 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 526.7/526.7 kB 32.8 MB/s eta 0:00:00\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip -q install pydicom opencv-python scikit-image pyradiomics\n",
        "\n",
        "wget -q http://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz && tar -xf imagens_ihq.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3d96161f-6336-49be-ae1a-5f50cbdf5e31",
      "metadata": {
        "id": "3d96161f-6336-49be-ae1a-5f50cbdf5e31"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "import pydicom as dicom\n",
        "import radiomics\n",
        "from radiomics import featureextractor\n",
        "import SimpleITK as sitk\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6364a4a5-2187-415e-83f8-3c6c59912354",
      "metadata": {
        "id": "6364a4a5-2187-415e-83f8-3c6c59912354"
      },
      "outputs": [],
      "source": [
        "def cut_images(input_path, new_width, new_height, output_path=None):\n",
        "    \"\"\"\n",
        "    Cut images into the desired size and save the output images\n",
        "\n",
        "    Params:\n",
        "    input_path = path to the original images\n",
        "    output_path = path to save the cut images\n",
        "    new_width = width of the cut images\n",
        "    new_height = height of the cut images\n",
        "\n",
        "    Return:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    images_data = {}\n",
        "    classes = []\n",
        "    patients = []\n",
        "\n",
        "    # Browse input path\n",
        "    for class_dir in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "\n",
        "        # If it is a directory\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "\n",
        "\n",
        "            # Save image id\n",
        "            image_id = 1\n",
        "\n",
        "            # Go through images\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                # Save patient id\n",
        "                patient = image_file.split(\"_\")[0]\n",
        "                patients.append(patient)\n",
        "\n",
        "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # If image exists\n",
        "                if image is not None:\n",
        "\n",
        "                    # Save subimage id\n",
        "                    sub_id = 1\n",
        "\n",
        "                    for i in range(0, image.shape[0], new_height):\n",
        "                        for j in range(0, image.shape[1], new_width):\n",
        "\n",
        "                            # Cut image into subimage\n",
        "                            sub_image = image[i:i+new_height, j:j+new_width]\n",
        "\n",
        "                            # Image name identifier\n",
        "                            image_name = f\"{patient}-img{image_id}-{sub_id}\"\n",
        "\n",
        "                            # Append image and its label to the dictionary\n",
        "                            images_data[image_name] = sub_image\n",
        "\n",
        "                            # images_names.append(image_name)\n",
        "                            # images.append(sub_image)\n",
        "\n",
        "                            classes.append(int(class_dir))\n",
        "\n",
        "\n",
        "                            # Write subimage if an output path was given\n",
        "                            if output_path != None:\n",
        "                                # Create dir if it doesn't exist\n",
        "                                os.makedirs(os.path.join(output_path, class_dir), exist_ok=True)\n",
        "                                # Output file path\n",
        "                                output_file = f\"{image_name}.png\"\n",
        "                                output_file = os.path.join(output_path, class_dir, output_file)\n",
        "                                # Save subimage\n",
        "                                cv.imwrite(output_file, sub_image)\n",
        "\n",
        "                            sub_id += 1\n",
        "\n",
        "                    image_id += 1\n",
        "\n",
        "    return (images_data, patients, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069",
      "metadata": {
        "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069"
      },
      "outputs": [],
      "source": [
        "def divide_folds(images, patients, classes):\n",
        "    \"\"\"\n",
        "    Divides a dataset into folds for stratified k-fold cross-validation.\n",
        "\n",
        "    Params:\n",
        "    images = list of all images\n",
        "    patients = list with patient id for each image\n",
        "    classes = list with class for each image\n",
        "\n",
        "    Return:\n",
        "    folds = list of tuples, each tuple is one folder\n",
        "    \"\"\"\n",
        "    # Create a list of unique indexes for patients\n",
        "    unique_patients = list(set(patients))\n",
        "\n",
        "    # Shuffle the list of unique indexes\n",
        "    random.shuffle(unique_patients)\n",
        "\n",
        "    # Divide patients into groups\n",
        "    n_folds = 4 # since it's not an exact division, there will be 5 folds\n",
        "    fold_size = len(unique_patients) // n_folds\n",
        "    patients_folds = [unique_patients[i:i+fold_size] for i in range(0, len(unique_patients), fold_size)]\n",
        "\n",
        "    # List to save folds\n",
        "    folds = []\n",
        "\n",
        "    # Divide images into folds based on patients\n",
        "    for i, patients_folds in enumerate(patients_folds):\n",
        "        train_patients = [p for p in unique_patients if p not in patients_folds]\n",
        "        test_patients = patients_folds\n",
        "\n",
        "        train_indices = [i for i, patient in enumerate(patients) if patient in train_patients]\n",
        "        test_indices = [i for i, patient in enumerate(patients) if patient in test_patients]\n",
        "\n",
        "        train_images = [images[i] for i in train_indices]\n",
        "        test_images = [images[i] for i in test_indices]\n",
        "        train_classes = [classes[i] for i in train_indices]\n",
        "        test_classes = [classes[i] for i in test_indices]\n",
        "\n",
        "        folds.append((train_images, test_images, train_classes, test_classes))\n",
        "\n",
        "    return folds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721",
      "metadata": {
        "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721"
      },
      "outputs": [],
      "source": [
        "def apply_thresholds(imgs):\n",
        "    \"\"\"\n",
        "    Apply Otsu's and Adaptative thresholds to images\n",
        "\n",
        "    Params:\n",
        "    imgs = list of raw images\n",
        "\n",
        "    Return:\n",
        "    imgs_otsu = Otsu's thresholded images\n",
        "    imgs_adapt = Adaptative thresholded images\n",
        "    \"\"\"\n",
        "\n",
        "    for key, value in images_data.items():\n",
        "\n",
        "        # Otsu's thresholding\n",
        "        _, th1 = cv.threshold(value, 100, 1, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "        # Adaptative gaussian thresholding\n",
        "        #th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n",
        "        th3 = cv.adaptiveThreshold(value, 1, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        images_data[key] = (value, th1, th3)\n",
        "\n",
        "    return images_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
      "metadata": {
        "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d"
      },
      "outputs": [],
      "source": [
        "# Cut images into 40x30\n",
        "images_data, patients, classes = cut_images(\"/content/imagens_ihq_er\", 40, 30)\n",
        "\n",
        "# Divide images into folds\n",
        "images_names = list(images_data.keys())\n",
        "folds = divide_folds(images_names, patients, classes)\n",
        "\n",
        "# Update images_data, applying Otsu's and adaptive thresholds\n",
        "images_data = apply_thresholds(images_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "blu = dict(itertools.islice(images_data.items(), 4))\n",
        "\n"
      ],
      "metadata": {
        "id": "0dfXgxzBj97e"
      },
      "id": "0dfXgxzBj97e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(blu.keys())"
      ],
      "metadata": {
        "id": "R3x7oAzeknHQ",
        "outputId": "9b78f81f-75ed-4ff7-fd71-128e9d3e607c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R3x7oAzeknHQ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['638RE-img1-1', '638RE-img1-2', '638RE-img1-3', '638RE-img1-4']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ff = [['638RE-img1-1', '638RE-img1-2'], [1, 2], ['638RE-img1-3', '638RE-img1-4'], [1, 2]]"
      ],
      "metadata": {
        "id": "8BHKOll8kKWG"
      },
      "id": "8BHKOll8kKWG",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec",
      "metadata": {
        "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec"
      },
      "source": [
        "Extract features with PyRadiomics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45",
      "metadata": {
        "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45"
      },
      "outputs": [],
      "source": [
        "def run_extractor(images_data, extractor):\n",
        "    \"\"\"\n",
        "    Extract features using sitk and pyradiomics\n",
        "\n",
        "    Params:\n",
        "    imgs = raw images\n",
        "    otsu = masked images with otsu thresholding\n",
        "    adapt = masked images with adaptative thresholding\n",
        "    extractor = pyradiomics extractor\n",
        "\n",
        "    Returns:\n",
        "    features_otsu = features for otsu mask\n",
        "    features_adapt = features for adaptative mask\n",
        "    \"\"\"\n",
        "\n",
        "    data_spacing=[1,1,1]\n",
        "    features_otsu = {}\n",
        "    features_adapt = {}\n",
        "\n",
        "    for key, value in images_data.items():\n",
        "\n",
        "        # Get raw, Otsu's and adaptive images\n",
        "        img = value[0]\n",
        "        img_otsu = value[1]\n",
        "        img_adapt = value[2]\n",
        "\n",
        "        sitk_img = sitk.GetImageFromArray(img)\n",
        "        sitk_img.SetSpacing((1, 1, 1))\n",
        "        sitk_img = sitk.JoinSeries(sitk_img)\n",
        "\n",
        "        sitk_otsu = sitk.GetImageFromArray(img_otsu)\n",
        "        sitk_otsu.SetSpacing((1, 1, 1))\n",
        "        sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
        "        sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        sitk_adapt = sitk.GetImageFromArray(img_adapt)\n",
        "        sitk_adapt.SetSpacing((1, 1, 1))\n",
        "        sitk_adapt = sitk.JoinSeries(sitk_adapt)\n",
        "        sitk_adapt = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        # Extract features and append them to the proper list\n",
        "        try:\n",
        "            ft_otsu = extractor.execute(sitk_img, sitk_otsu)\n",
        "            features_otsu[key] = ft_otsu\n",
        "\n",
        "            ft_adapt = extractor.execute(sitk_img, sitk_adapt)\n",
        "            features_adapt[key] = ft_adapt\n",
        "\n",
        "        except:\n",
        "            #print(f\"{key}, \", end=\"\")\n",
        "            pass\n",
        "\n",
        "    return (features_otsu, features_adapt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "283f005e-92be-49b2-b869-f622389d0a68",
      "metadata": {
        "id": "283f005e-92be-49b2-b869-f622389d0a68"
      },
      "outputs": [],
      "source": [
        "def conditional_append(element, dest):\n",
        "    \"\"\"\n",
        "    Append element to the list destiny, if element is not in destiny\n",
        "\n",
        "    Params:\n",
        "    element = an element of any kind\n",
        "    dest = a destination list\n",
        "\n",
        "    Returns:\n",
        "    destiny = list with appended element if the element was not in there\n",
        "    \"\"\"\n",
        "    if element not in dest:\n",
        "        dest.append(element)\n",
        "\n",
        "    return dest\n",
        "\n",
        "def process_features(feats_o, feats_a):\n",
        "    \"\"\"\n",
        "    Process features, in a way that:\n",
        "    - features that are dictionaries and strings are removed\n",
        "    - features that are tuples are separated and each element\n",
        "    of the tuple is considered one feature\n",
        "    - other types are converted to float\n",
        "\n",
        "    Params:\n",
        "    feats_o = list of Otsu's threshold features\n",
        "    feats_a = list of adaptativa threshold features\n",
        "\n",
        "    Returns:\n",
        "    all_feats_o = Otsu's features processed\n",
        "    all_feats_a = adaptative features processed\n",
        "    names = feature names processed\n",
        "    \"\"\"\n",
        "\n",
        "    all_feats_o = {}\n",
        "    all_feats_a = {}\n",
        "    names = []\n",
        "\n",
        "    # For each image in one of the features list\n",
        "    for key in feats_o:\n",
        "\n",
        "        # Get features for Otsu's and adaptive for this sample\n",
        "        sample_o = feats_o[key]\n",
        "        sample_a = feats_a[key]\n",
        "\n",
        "        values_o = []\n",
        "        values_a = []\n",
        "\n",
        "        # For each feature in the list\n",
        "        for ft in sample_o:\n",
        "\n",
        "            # Get the feature's value\n",
        "            value_o = sample_o[ft]\n",
        "            value_a = sample_a[ft]\n",
        "\n",
        "            # If the value is str or dict, ignore it\n",
        "            if type(value_o) == str or type(value_o) == dict:\n",
        "                continue\n",
        "            # If it's a tuple\n",
        "            elif type(value_o) == tuple:\n",
        "                for e in range(len(value_o)):\n",
        "                    # Add and index to the feature name\n",
        "                    conditional_append(f'{ft}_{e}', names)\n",
        "                    # Append float values to the lists\n",
        "                    values_o.append(float(value_o[e]))\n",
        "                    values_a.append(float(value_a[e]))\n",
        "            # For other data types, just append the name and float values\n",
        "            else:\n",
        "                conditional_append(ft, names)\n",
        "                values_o.append(float(value_o))\n",
        "                values_a.append(float(value_a))\n",
        "\n",
        "        # Append processed features to the general list\n",
        "        all_feats_o[key] = values_o\n",
        "        all_feats_a[key] = values_a\n",
        "\n",
        "    return (all_feats_o, all_feats_a, names)\n",
        "\n",
        "def extract_features(images_data):\n",
        "    \"\"\"\n",
        "    Process features, in a way that:\n",
        "    - features that are dictionaries and strings are removed\n",
        "    - features that are tuples are separated and each element\n",
        "    of the tuple is considered one feature\n",
        "    - other types are converted to float\n",
        "    Get the features' names, with tuple features indexed\n",
        "\n",
        "    Params:\n",
        "    folds = list of tuples containing x_train raw and with thresholds\n",
        "\n",
        "    Returns:\n",
        "    all_folds_feats = dictionary containing Otsu's features and adaptive\n",
        "    features for each fold\n",
        "    names = feature names\n",
        "    \"\"\"\n",
        "\n",
        "    # Create feature extractor\n",
        "    !wget -c https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
        "    params = 'Params.yaml'\n",
        "    settings = {'label': 1, 'correctMask': True}\n",
        "    extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True, **settings)\n",
        "\n",
        "    # Extract features from Otsu's and adaptative\n",
        "    feats_o, feats_a = run_extractor(images_data, extractor)\n",
        "\n",
        "    # Process features and get feature names\n",
        "    all_feats_o, all_feats_a, names = process_features(feats_o, feats_a)\n",
        "\n",
        "    # Save features in the dictionary\n",
        "    # keys = list(images_data.keys())\n",
        "    # for i in range(len(images_data)):\n",
        "    #     key = key[i]\n",
        "    #     value = images_data[key]\n",
        "    #     images_data[key] = (value[0], value[1], value[2], all_feats_o[i], all_feats_a[i])\n",
        "\n",
        "    return (all_feats_o, all_feats_a, names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c20992f0-183f-4cff-b718-67608f9100ff",
      "metadata": {
        "id": "c20992f0-183f-4cff-b718-67608f9100ff",
        "outputId": "508f2c2a-518e-45d5-cb26-d84d1f2611a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 23:46:08--  https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:radiomics.featureextractor:Loading parameter file Params.yaml\n",
            "INFO:radiomics.featureextractor:Applying custom setting overrides: {'additionalInfo': True, 'label': 1, 'correctMask': True}\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7afcee847066>\u001b[0m in \u001b[0;36mrun_extractor\u001b[0;34m(images_data, extractor)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mft_otsu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msitk_otsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mfeatures_otsu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_otsu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/radiomics/featureextractor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, imageFilepath, maskFilepath, label, label_channel, voxelBased)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mfeatureVector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageFilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskFilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneralInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/radiomics/featureextractor.py\u001b[0m in \u001b[0;36mloadImage\u001b[0;34m(ImageFilePath, MaskFilePath, generalInfo, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# process the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageoperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/radiomics/imageoperations.py\u001b[0m in \u001b[0;36mgetMask\u001b[0;34m(mask, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No labels found in this mask (i.e. nothing is segmented)!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No labels found in this mask (i.e. nothing is segmented)!",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8a3903d9ce76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_feats_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_feats_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f6c924ab421b>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(images_data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Extract features from Otsu's and adaptative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mfeats_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# Process features and get feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-7afcee847066>\u001b[0m in \u001b[0;36mrun_extractor\u001b[0;34m(images_data, extractor)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"AAAAAAAAAAAAA{idx}, \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
          ]
        }
      ],
      "source": [
        "all_feats_o, all_feats_a, names = extract_features(blu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_feats_o)"
      ],
      "metadata": {
        "id": "aSrNAAe3ktjn",
        "outputId": "c1df12e6-c0ba-457c-be69-3c105d5f1aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aSrNAAe3ktjn",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3VzTAqtkwpw"
      },
      "id": "I3VzTAqtkwpw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}