{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install pydicom opencv-python scikit-image\n",
    "# pip install pyradiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d96161f-6336-49be-ae1a-5f50cbdf5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "import pydicom as dicom\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import SimpleITK as sitk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364a4a5-2187-415e-83f8-3c6c59912354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_images(input_path, output_path, new_width, new_height):\n",
    "    \"\"\"\n",
    "    Cut images into the desired size and save the output images\n",
    "    \n",
    "    Params:  \n",
    "    input_path = path to the original images \n",
    "    output_path = path to save the cut images\n",
    "    new_width = width of the cut images\n",
    "    new_height = height of the cut images\n",
    "    \n",
    "    Return:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create dir if it doesn't exist \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    n_images = 0\n",
    "\n",
    "    # Browse input path\n",
    "    for class_dir in os.listdir(input_path):\n",
    "        class_path = os.path.join(input_path, class_dir)\n",
    "\n",
    "        # If it is a directory \n",
    "        if os.path.isdir(class_path):     \n",
    "\n",
    "            # Save image id\n",
    "            image_id = 1\n",
    "\n",
    "            # Go through images\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                # Save patient id\n",
    "                patient = image_file.split(\"_\")[0]                         \n",
    "\n",
    "                image = cv.imread(image_path)\n",
    "\n",
    "                # If image exists\n",
    "                if image is not None:\n",
    "\n",
    "                    # Save subimage id\n",
    "                    sub_id = 1\n",
    "\n",
    "                    for i in range(0, image.shape[0], new_height):\n",
    "                        for j in range(0, image.shape[1], new_width):\n",
    "\n",
    "                            # Cut image into subimage\n",
    "                            sub_image = image[i:i+new_height, j:j+new_width]\n",
    "\n",
    "                            # Output file path\n",
    "                            output_file = f\"{patient}_img{image_id}-{sub_id}.png\"                   \n",
    "                            output_file = os.path.join(output_path, class_dir, output_file)                        \n",
    "\n",
    "                            # Save subimage\n",
    "                            cv.imwrite(output_file, sub_image)                 \n",
    "\n",
    "                            sub_id += 1\n",
    "                            n_images += 1\n",
    "\n",
    "                    image_id += 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54a4d795-c9a9-49b4-8f07-2f43233fa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(input_path):\n",
    "    \"\"\"\n",
    "    Read images in the input_path, \n",
    "    save image, patient of each image and the class (group/labels)\n",
    "    \n",
    "    Params: \n",
    "    input_path = path to the original images \n",
    "    \n",
    "    Return:\n",
    "    images = list of all images\n",
    "    patients = list with patient id for each image\n",
    "    classes = list with class for each image\n",
    "    \"\"\"\n",
    "   \n",
    "    # Lists to save images, patients and classes\n",
    "    images = []\n",
    "    patients = []\n",
    "    classes = []\n",
    "\n",
    "    # Browse input path\n",
    "    for class_dir in os.listdir(input_path):\n",
    "        class_path = os.path.join(input_path, class_dir)\n",
    "\n",
    "        # If it is a directory \n",
    "        if os.path.isdir(class_path):    \n",
    "\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                patient = image_file.split(\"_\")[0]             \n",
    "\n",
    "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Append image, patient id and class to list\n",
    "                images.append(image)\n",
    "                patients.append(patient)\n",
    "                classes.append(class_dir)    \n",
    "                \n",
    "    return (images, patients, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_folds(images, patients, classes):\n",
    "    \"\"\"\n",
    "    Divides a dataset into folds for stratified k-fold cross-validation.\n",
    "    \n",
    "    Params: \n",
    "    images = list of all images\n",
    "    patients = list with patient id for each image\n",
    "    classes = list with class for each image\n",
    "    \n",
    "    Return:\n",
    "    folds = list of tuples, each tuple is one folder\n",
    "    \"\"\"\n",
    "    # Create a list of unique indexes for patients\n",
    "    unique_patients = list(set(patients))\n",
    "\n",
    "    # Shuffle the list of unique indexes\n",
    "    random.shuffle(unique_patients)\n",
    "\n",
    "    # Divide patients into groups\n",
    "    n_folds = 4 # since it's not an exact division, there will be 5 folds\n",
    "    fold_size = len(unique_patients) // n_folds\n",
    "    patients_folds = [unique_patients[i:i+fold_size] for i in range(0, len(unique_patients), fold_size)]\n",
    "\n",
    "    # List to save folds\n",
    "    folds = []\n",
    "\n",
    "    # Divide images into folds based on patients\n",
    "    for i, patients_folds in enumerate(patients_folds):\n",
    "        train_patients = [p for p in unique_patients if p not in patients_folds]\n",
    "        test_patients = patients_folds\n",
    "\n",
    "        train_indices = [i for i, patient in enumerate(patients) if patient in train_patients]\n",
    "        test_indices = [i for i, patient in enumerate(patients) if patient in test_patients]\n",
    "\n",
    "        train_images = [images[i] for i in train_indices]\n",
    "        test_images = [images[i] for i in test_indices]\n",
    "        train_classes = [classes[i] for i in train_indices]\n",
    "        test_classes = [classes[i] for i in test_indices]\n",
    "\n",
    "        folds.append((train_images, test_images, train_classes, test_classes))\n",
    "        \n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholds(imgs):    \n",
    "    \"\"\"\n",
    "    Apply Otsu's and Adaptative thresholds to images\n",
    "    \n",
    "    Params: \n",
    "    imgs = list of raw images\n",
    "    \n",
    "    Return: \n",
    "    imgs_otsu = Otsu's thresholded images\n",
    "    imgs_adapt = Adaptative thresholded images    \n",
    "    \"\"\"\n",
    "    \n",
    "    imgs_otsu = []\n",
    "    imgs_adapt = []\n",
    "    \n",
    "    # For each image in dataset                          \n",
    "    for img in imgs: \n",
    "        \n",
    "        # Otsu's thresholding\n",
    "        _, th1 = cv.threshold(img, 100, 1, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        \n",
    "        # Adaptative gaussian thresholding        \n",
    "        #th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n",
    "        th3 = cv.adaptiveThreshold(img, 1, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
    "               \n",
    "        imgs_otsu.append(th1)\n",
    "        imgs_adapt.append(th3)    \n",
    "        \n",
    "    return (imgs_otsu, imgs_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7cfa20-c693-47ef-acfc-3a17fa27ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_folds(folds):\n",
    "    \"\"\"\n",
    "    For each fold, add Otsu's and adaptive\n",
    "    thresholding of all test and train images\n",
    "    \n",
    "    Params:\n",
    "    folds = list of tuples containing the images divided in folds\n",
    "    \n",
    "    Returns:\n",
    "    new_folds = updated list of tuples containing the images and masks divided in folds\n",
    "    \"\"\"\n",
    "    \n",
    "    new_folds = []\n",
    "    \n",
    "    # For each fold\n",
    "    for i in range(len(folds)):\n",
    "        fold = folds[i]        \n",
    "\n",
    "        x_train = fold[0]\n",
    "        x_test = fold[1]\n",
    "        y_train = fold[2]\n",
    "        y_test = fold[3]\n",
    "\n",
    "        x_train_otsu, x_train_adapt = apply_thresholds(x_train)\n",
    "        #x_test_otsu, x_test_adapt = apply_thresholds(x_test)  \n",
    "\n",
    "        # Update list with the thresholds   \n",
    "        new_folds.append((x_train, x_train_otsu, x_train_adapt, x_test, y_train, y_test))\n",
    "        #new_folds[i] = (x_train, x_train_otsu, x_train_adapt, x_test, x_test_otsu, x_test_adapt, y_train, y_test)\n",
    "        \n",
    "    return new_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../folds.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cut images into 40x30\n",
    "#cut_images(\"imagens_ihq_er\", \"imagens_cortadas\", 40, 30)\n",
    "\n",
    "# Save images, patients and classes\n",
    "images, patients, classes = read_images(\"imagens_cortadas\")\n",
    "\n",
    "# Divide images into folds\n",
    "folds = divide_folds(images, patients, classes)\n",
    "\n",
    "# Apply Otsu's and adaptive thresholds\n",
    "folds = update_folds(folds)\n",
    "\n",
    "# Save folds\n",
    "dump(folds, '../folds.joblib')\n",
    "\n",
    "# Load folds\n",
    "# folds = load('../folds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67be011-d4cc-4466-9ee2-db590c153ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load folds\n",
    "folds = load('../folds.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec",
   "metadata": {},
   "source": [
    "Extract features with PyRadiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, otsu, adapt, extractor):    \n",
    "    \"\"\"\n",
    "    Extract features using sitk and pyradiomics\n",
    "    \n",
    "    Params:\n",
    "    imgs = raw images\n",
    "    otsu = masked images with otsu thresholding\n",
    "    adapt = masked images with adaptative thresholding\n",
    "    extractor = pyradiomics extractor\n",
    "    \n",
    "    Returns:\n",
    "    features_otsu = features for otsu mask\n",
    "    features_adapt = features for adaptative mask\n",
    "    \"\"\"\n",
    "    \n",
    "    data_spacing=[1,1,1]\n",
    "    features_otsu = []\n",
    "    features_adapt = []\n",
    "    \n",
    "    n = 0\n",
    "        \n",
    "    for idx in range(len(imgs)): \n",
    "\n",
    "        img = imgs[idx]\n",
    "        img_otsu = otsu[idx]\n",
    "        img_adapt = adapt[idx]\n",
    "\n",
    "        sitk_img = sitk.GetImageFromArray(img)\n",
    "        sitk_img.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2])))\n",
    "        sitk_img = sitk.JoinSeries(sitk_img)\n",
    "\n",
    "        sitk_otsu = sitk.GetImageFromArray(img_otsu)\n",
    "        sitk_otsu.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2])))\n",
    "        sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
    "        sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
    "\n",
    "        sitk_adapt = sitk.GetImageFromArray(img_adapt)\n",
    "        sitk_adapt.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2])))\n",
    "        sitk_adapt = sitk.JoinSeries(sitk_adapt)\n",
    "        sitk_adapt = sitk.Cast(sitk_otsu, sitk.sitkInt32)       \n",
    "        \n",
    "        try:\n",
    "            features_otsu.append(extractor.execute(sitk_img, sitk_otsu))\n",
    "            features_adapt.append(extractor.execute(sitk_img, sitk_adapt))\n",
    "            n += 1      \n",
    "                \n",
    "        except: \n",
    "            print(f\"{n}, \", end=\"\")\n",
    "            pass          \n",
    "        \n",
    "    return (features_otsu, features_adapt)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03251dd4-4ec9-47f0-8a7d-c9df9fcc1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk_otsu = sitk.GetImageFromArray(o[0])\n",
    "sitk_otsu.SetSpacing((1, 1, 1))\n",
    "sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
    "sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
    "\n",
    "sitk_img = sitk.GetImageFromArray(data[0])\n",
    "sitk_img.SetSpacing((1, 1, 1))\n",
    "sitk_img = sitk.JoinSeries(sitk_img)\n",
    "\n",
    "#extractor.execute(sitk_img, sitk_otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98a31341-4b43-40ba-8c68-49d1bdba2a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 30, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitk_otsu.GetSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12400979-b436-4886-b662-a3881c130e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds[0][1][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47b6a0-a6d1-4eaf-96da-9b5482f4c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ft_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf9bcd-3524-49d9-baad-2b7e8d9a7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folds[0][0]\n",
    "o = folds[0][1]\n",
    "a = folds[0][2]\n",
    "ft_o, ft_a = extract_features(data, o, a, extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36e6246-e994-403f-98a5-72dc888c38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_o[0]['diagnostics_Versions_Numpy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f691b44-c759-4cc7-ad31-512f902466af",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK new_Image: /tmp/SimpleITK/Code/Common/src/sitkImageExplicit.cxx:121:\nsitk::ERROR: Unsupported number of dimensions specified by size: [ 40 ]!\nThe maximum supported Image dimension is 5.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7400/3563095645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#     # Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mfeats_train_otsu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_train_adapt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_otsu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_adapt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;31m#feats_test_otsu, feats_test_adapt = extract_features(x_test, x_test_otsu, x_test_adapt, extractor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7400/1839621516.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(imgs, otsu, adapt, extractor)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msitk_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJoinSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msitk_otsu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetImageFromArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0msitk_otsu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetSpacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_spacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_spacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_spacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msitk_otsu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJoinSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk_otsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36mGetImageFromArray\u001b[0;34m(arr, isVector)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# SimpleITK throws an exception if the image dimension is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0m_SetImageFromArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3127\u001b[0m         \"\"\"\n\u001b[0;32m-> 3128\u001b[0;31m         \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage_swiginit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetITKBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK new_Image: /tmp/SimpleITK/Code/Common/src/sitkImageExplicit.cxx:121:\nsitk::ERROR: Unsupported number of dimensions specified by size: [ 40 ]!\nThe maximum supported Image dimension is 5."
     ]
    }
   ],
   "source": [
    "# Create feature extractor\n",
    "# !wget -c https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
    "params = 'Params.yaml'\n",
    "settings = {'label': 1, 'correctMask': True}\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True, **settings)\n",
    "\n",
    "# Extract features\n",
    "\n",
    "features_otsu = {}\n",
    "features_adapt = {}\n",
    "\n",
    "# For each fold\n",
    "for i in range(1):\n",
    "    \n",
    "    fold = folds[i]\n",
    "               \n",
    "    x_train = fold[0]\n",
    "    x_train_otsu = fold[1]\n",
    "    x_train_adapt = fold[2]\n",
    "\n",
    "    \n",
    "    # Create dataframe to save features\n",
    "#     df_train_otsu = pd.DataFrame()\n",
    "#     df_train_adapt = pd.DataFrame()\n",
    "\n",
    "    \n",
    "#     # Extract features\n",
    "    feats_train_otsu, feats_train_adapt = extract_features(x_train, x_train_otsu, x_train_adapt, extractor)\n",
    "    \n",
    "    # Filter features and fix data types\n",
    "    \n",
    "    # em construção\n",
    "    \n",
    "#     features_otsu_filtered = []\n",
    "#     features_adapt_filtered = []\n",
    "#     features_names = []\n",
    "#     names = list(features_otsu.keys())\n",
    "    \n",
    "#     for j in range(len(features_otsu)):\n",
    "#         fo = features_otsu[j]\n",
    "#         fa = features_adapt[j]\n",
    "#         name = names[j]\n",
    "        \n",
    "#         if type(fo) == np.ndarray:\n",
    "#             fo = float(fo)\n",
    "#         else if type(fo) == dict:\n",
    "#             fo = NA       \n",
    "#         else if type(fo) == tuple:\n",
    "#             indexes = []\n",
    "#             for e in range(len(fo)):\n",
    "#                 indexes.append(e)\n",
    "#                 fo[e] = float(fo[e])\n",
    "   \n",
    "    \n",
    "#     df_train_otsu.columns = names\n",
    "#     df_test_adapt.columns = names\n",
    "#     df_train_otsu.columns = names\n",
    "#     df_test_adapt.columns = names\n",
    "\n",
    "#     fold_id = i+1\n",
    "#     features_dict[fold_id] = (df_train_otsu, df_test_otsu, df_train_adapt, df_test_adapt, y_train, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f264f87-8042-40d1-a15c-f380d0f0ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save folds\n",
    "dump(feats_train_otsu, '../feats_train_otsu.joblib')\n",
    "dump(feats_train_adapt, '../feats_train_otsu.joblib')\n",
    "dump(feats_test_otsu, '../feats_train_otsu.joblib')\n",
    "dump(feats_test_adapt, '../feats_train_otsu.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451dcde-2b74-4ac2-b577-d0b52675991e",
   "metadata": {},
   "source": [
    "Testando pra ver como pegar as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fded5ae1-bffb-426c-9fe5-0bc5039f02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 1, 0 = imagens, 1 = segundo \n",
    "test_img = folds[1][0][1]\n",
    "# fold 1, 1 = imagens com otsu, 1 = segundo elemento\n",
    "otsu = folds[1][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb6fb6d-23f3-4f0b-aaa2-9125087ee1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spacing=[1,1,1]\n",
    "sitk_img = sitk.GetImageFromArray(test_img)\n",
    "sitk_img.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
    "sitk_img = sitk.JoinSeries(sitk_img)\n",
    "\n",
    "sitk_mask = sitk.GetImageFromArray(otsu)\n",
    "sitk_mask.SetSpacing((float(data_spacing[0]), float(data_spacing[1]), float(data_spacing[2]) ))\n",
    "sitk_mask = sitk.JoinSeries(sitk_mask)\n",
    "sitk_mask = sitk.Cast(sitk_mask, sitk.sitkInt32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a5e900-ee50-4142-9dd3-808e48b4d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor.execute(sitk_img, sitk_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eed66797-7412-497b-93e1-2b484fffb6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2adb7914-fbc3-4390-b261-23e3b37ff8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021795298681438015"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(list(features.values())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f36c2921-08e9-4b82-a1f3-1dab7db0d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in list(features.values()):\n",
    "    print(type(i) == str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8e78e4-300e-4e2a-9c76-e93f459a2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostics_Versions_PyRadiomics v3.1.0\n",
      "diagnostics_Versions_Numpy 1.24.3\n",
      "diagnostics_Versions_SimpleITK 2.3.0\n",
      "diagnostics_Versions_PyWavelet 1.3.0\n",
      "diagnostics_Versions_Python 3.9.13\n",
      "diagnostics_Configuration_Settings {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 255, 'additionalInfo': True, 'binWidth': 25, 'weightingNorm': None}\n",
      "diagnostics_Configuration_EnabledImageTypes {'Original': {}}\n",
      "diagnostics_Image-original_Hash ae37fbfe4969d0864fb25c3fecab05ec1787adac\n",
      "diagnostics_Image-original_Dimensionality 3D\n",
      "diagnostics_Image-original_Spacing (1.0, 1.0, 1.0)\n",
      "diagnostics_Image-original_Size (40, 30, 1)\n",
      "diagnostics_Image-original_Mean 182.48333333333332\n",
      "diagnostics_Image-original_Minimum 74.0\n",
      "diagnostics_Image-original_Maximum 255.0\n",
      "diagnostics_Mask-original_Hash 655cfb8d0ad15a412d717bc98f922ee2ec6f04ee\n",
      "diagnostics_Mask-original_Spacing (1.0, 1.0, 1.0)\n",
      "diagnostics_Mask-original_Size (40, 30, 1)\n",
      "diagnostics_Mask-original_BoundingBox (0, 0, 0, 40, 30, 1)\n",
      "diagnostics_Mask-original_VoxelNum 638\n",
      "diagnostics_Mask-original_VolumeNum 3\n",
      "diagnostics_Mask-original_CenterOfMassIndex (26.954545454545453, 16.387147335423197, 0.0)\n",
      "diagnostics_Mask-original_CenterOfMass (26.954545454545453, 16.387147335423197, 0.0)\n",
      "original_shape_Elongation 0.7094650213812403\n",
      "original_shape_Flatness 0.0\n",
      "original_shape_LeastAxisLength 0.0\n",
      "original_shape_MajorAxisLength 41.29884141070391\n",
      "original_shape_Maximum2DDiameterColumn 40.0\n",
      "original_shape_Maximum2DDiameterRow 30.0\n",
      "original_shape_Maximum2DDiameterSlice 49.4064773081425\n",
      "original_shape_Maximum3DDiameter 49.4064773081425\n",
      "original_shape_MeshVolume 601.6666666666666\n",
      "original_shape_MinorAxisLength 29.300083404465504\n",
      "original_shape_Sphericity 0.2570842831673996\n",
      "original_shape_SurfaceArea 1340.6412107135714\n",
      "original_shape_SurfaceVolumeRatio 2.228212538582113\n",
      "original_shape_VoxelVolume 638.0\n",
      "original_firstorder_10Percentile 220.7\n",
      "original_firstorder_90Percentile 254.0\n",
      "original_firstorder_Energy 37509863.0\n",
      "original_firstorder_Entropy 1.5104876972356283\n",
      "original_firstorder_InterquartileRange 13.0\n",
      "original_firstorder_Kurtosis 7.136994352541768\n",
      "original_firstorder_Maximum 255.0\n",
      "original_firstorder_MeanAbsoluteDeviation 11.138442035750435\n",
      "original_firstorder_Mean 241.9294670846395\n",
      "original_firstorder_Median 247.0\n",
      "original_firstorder_Minimum 179.0\n",
      "original_firstorder_Range 76.0\n",
      "original_firstorder_RobustMeanAbsoluteDeviation 5.92901785714286\n",
      "original_firstorder_RootMeanSquared 242.47244939319094\n",
      "original_firstorder_Skewness -2.1257070236433657\n",
      "original_firstorder_TotalEnergy 37509863.0\n",
      "original_firstorder_Uniformity 0.4007134363852557\n",
      "original_firstorder_Variance 263.0216708758758\n",
      "original_glcm_Autocorrelation 11.430252556805964\n",
      "original_glcm_JointAverage 3.3287935814572673\n",
      "original_glcm_ClusterProminence 11.272758117426303\n",
      "original_glcm_ClusterShade -1.9415682045830591\n",
      "original_glcm_ClusterTendency 1.6541689077316268\n",
      "original_glcm_Contrast 0.2583333002801104\n",
      "original_glcm_Correlation 0.7270977788480786\n",
      "original_glcm_DifferenceAverage 0.22434486772517698\n",
      "original_glcm_DifferenceEntropy 0.8187293902250552\n",
      "original_glcm_DifferenceVariance 0.20755424694718724\n",
      "original_glcm_JointEnergy 0.3051178091884267\n",
      "original_glcm_JointEntropy 2.2148220680567547\n",
      "original_glcm_Imc1 -0.39429007513100667\n",
      "original_glcm_Imc2 0.8116556419012224\n",
      "original_glcm_Idm 0.891226409392905\n",
      "original_glcm_Idmn 0.985432080726089\n",
      "original_glcm_Id 0.89338069775371\n",
      "original_glcm_Idn 0.956251219104755\n",
      "original_glcm_InverseVariance 0.19565905669992772\n",
      "original_glcm_MaximumProbability 0.40143484562614007\n",
      "original_glcm_SumEntropy 1.9471325444081624\n",
      "original_glcm_SumSquares 0.4781255520029343\n",
      "original_glrlm_GrayLevelNonUniformity 52.43335882166189\n",
      "original_glrlm_GrayLevelNonUniformityNormalized 0.29399292863171045\n",
      "original_glrlm_GrayLevelVariance 0.9518946014963084\n",
      "original_glrlm_HighGrayLevelRunEmphasis 8.625139428930522\n",
      "original_glrlm_LongRunEmphasis 28.05546783970255\n",
      "original_glrlm_LongRunHighGrayLevelEmphasis 355.70876737133915\n",
      "original_glrlm_LongRunLowGrayLevelEmphasis 2.7111987498274863\n",
      "original_glrlm_LowGrayLevelRunEmphasis 0.25336232937548275\n",
      "original_glrlm_RunEntropy 4.197789343816262\n",
      "original_glrlm_RunLengthNonUniformity 44.7022698522577\n",
      "original_glrlm_RunLengthNonUniformityNormalized 0.24938248991746137\n",
      "original_glrlm_RunPercentage 0.27860501567398116\n",
      "original_glrlm_RunVariance 14.775792734995814\n",
      "original_glrlm_ShortRunEmphasis 0.5076331452072009\n",
      "original_glrlm_ShortRunHighGrayLevelEmphasis 3.255765890817306\n",
      "original_glrlm_ShortRunLowGrayLevelEmphasis 0.19034162497023854\n",
      "original_glszm_GrayLevelNonUniformity 10.636363636363637\n",
      "original_glszm_GrayLevelNonUniformityNormalized 0.32231404958677684\n",
      "original_glszm_GrayLevelVariance 1.0266299357208448\n",
      "original_glszm_HighGrayLevelZoneEmphasis 5.2727272727272725\n",
      "original_glszm_LargeAreaEmphasis 4015.5151515151515\n",
      "original_glszm_LargeAreaHighGrayLevelEmphasis 46797.878787878784\n",
      "original_glszm_LargeAreaLowGrayLevelEmphasis 380.2114898989899\n",
      "original_glszm_LowGrayLevelZoneEmphasis 0.45896464646464646\n",
      "original_glszm_SizeZoneNonUniformity 7.666666666666667\n",
      "original_glszm_SizeZoneNonUniformityNormalized 0.23232323232323232\n",
      "original_glszm_SmallAreaEmphasis 0.46929700542860164\n",
      "original_glszm_SmallAreaHighGrayLevelEmphasis 1.8702106372197798\n",
      "original_glszm_SmallAreaLowGrayLevelEmphasis 0.2488389591882551\n",
      "original_glszm_ZoneEntropy 3.5220053024636755\n",
      "original_glszm_ZonePercentage 0.05172413793103448\n",
      "original_glszm_ZoneVariance 3641.7373737373737\n",
      "original_gldm_DependenceEntropy 3.8036238627670405\n",
      "original_gldm_DependenceNonUniformity 137.58620689655172\n",
      "original_gldm_DependenceNonUniformityNormalized 0.21565236190682088\n",
      "original_gldm_DependenceVariance 5.681174516759859\n",
      "original_gldm_GrayLevelNonUniformity 255.6551724137931\n",
      "original_gldm_GrayLevelVariance 0.6078163540059551\n",
      "original_gldm_HighGrayLevelEmphasis 11.094043887147336\n",
      "original_gldm_LargeDependenceEmphasis 51.529780564263326\n",
      "original_gldm_LargeDependenceHighGrayLevelEmphasis 632.0595611285266\n",
      "original_gldm_LargeDependenceLowGrayLevelEmphasis 4.909341257401602\n",
      "original_gldm_LowGrayLevelEmphasis 0.14408089515848138\n",
      "original_gldm_SmallDependenceEmphasis 0.05996358953717329\n",
      "original_gldm_SmallDependenceHighGrayLevelEmphasis 0.41509912119671977\n",
      "original_gldm_SmallDependenceLowGrayLevelEmphasis 0.021795298681438015\n"
     ]
    }
   ],
   "source": [
    "for key, val in enumerate(features):\n",
    "    print(val, features[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500d076-2196-4557-94c5-a8e0afeb7676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
