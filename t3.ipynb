{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0b2b583-c1da-4b2e-b4df-2d4ac65e97e6",
        "outputId": "7227ac19-97f5-40a0-965c-a7040265b636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 12.2 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 17.5 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 12.1 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 11.9 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.4/116.4 kB 15.5 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 526.7/526.7 kB 50.1 MB/s eta 0:00:00\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip -q install pydicom opencv-python scikit-image pyradiomics\n",
        "\n",
        "wget -q http://www.inf.ufpr.br/lferrari/imagens_ihq.tar.gz && tar -xf imagens_ihq.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "NOphUOjaSsq0",
      "metadata": {
        "id": "NOphUOjaSsq0"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "# import pydicom as dicom\n",
        "# import radiomics\n",
        "# from radiomics import featureextractor\n",
        "# import SimpleITK as sitk\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from joblib import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6364a4a5-2187-415e-83f8-3c6c59912354",
      "metadata": {
        "id": "6364a4a5-2187-415e-83f8-3c6c59912354"
      },
      "outputs": [],
      "source": [
        "def cut_images(input_path, new_width, new_height, output_path=None):\n",
        "    \"\"\"\n",
        "    Cut images into the desired size and save the output images\n",
        "\n",
        "    Params:\n",
        "    input_path: path to the original images\n",
        "    output_path: path to save the cut images\n",
        "    new_width: width of the cut images\n",
        "    new_height: height of the cut images\n",
        "\n",
        "    Return:\n",
        "\n",
        "    images_data: dictionary with images names as keys\n",
        "    and images as values\n",
        "    patients: list of patients IDs\n",
        "    classes = list of labels\n",
        "    \"\"\"\n",
        "    images_data = {}\n",
        "    classes = []\n",
        "    patients = []\n",
        "\n",
        "    n = 0\n",
        "    # Browse input path\n",
        "    for class_dir in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "\n",
        "        # If it is a directory\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            # Save image id\n",
        "            image_id = 1\n",
        "\n",
        "            # Go through images\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                # Save patient id\n",
        "                patient = image_file.split(\"_\")[0]\n",
        "                patients.append(patient)\n",
        "\n",
        "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # If image exists\n",
        "                if image is not None:\n",
        "\n",
        "                    # Save subimage id\n",
        "                    sub_id = 1\n",
        "\n",
        "                    for i in range(0, image.shape[0], new_height):\n",
        "                        for j in range(0, image.shape[1], new_width):\n",
        "\n",
        "                            # Cut image into subimage\n",
        "                            sub_image = image[i:i+new_height, j:j+new_width]\n",
        "\n",
        "                            # Image name identifier\n",
        "                            image_name = f\"{patient}-img{image_id}-{sub_id}\"\n",
        "\n",
        "                            # Append image and its label to the dictionary\n",
        "                            # if image_name not in images_data:\n",
        "                            #     image_name = f\"{patient}2-img{image_id}-{sub_id}\"\n",
        "                            #     images_data[image_name] = sub_image\n",
        "                            # else:\n",
        "                            images_data[image_name] = sub_image\n",
        "\n",
        "                            classes.append(int(class_dir))\n",
        "\n",
        "                            # Write subimage if an output path was given\n",
        "                            if output_path != None:\n",
        "                                # Create dir if it doesn't exist\n",
        "                                os.makedirs(os.path.join(output_path, class_dir), exist_ok=True)\n",
        "                                # Output file path\n",
        "                                output_file = f\"{image_name}.png\"\n",
        "                                output_file = os.path.join(output_path, class_dir, output_file)\n",
        "                                # Save subimage\n",
        "                                cv.imwrite(output_file, sub_image)\n",
        "\n",
        "                            sub_id += 1\n",
        "                            n += 1\n",
        "\n",
        "                image_id += 1\n",
        "\n",
        "    return images_data, patients, classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069",
      "metadata": {
        "id": "2b932850-3b26-48ae-b7fd-84bc4b01f069"
      },
      "outputs": [],
      "source": [
        "def divide_folds(image_names, patients, classes):\n",
        "    \"\"\"\n",
        "    Divides a dataset into folds for stratified k-fold cross-validation.\n",
        "\n",
        "    Params:\n",
        "    images_names: list of all images names\n",
        "    patients: list with patient id for each image\n",
        "    classes: list with class for each image\n",
        "\n",
        "    Return:\n",
        "    folds: list of tuples, each tuple is one fold containing (imgs_names, labels)\n",
        "    \"\"\"\n",
        "    # Create a list of unique indexes for patients\n",
        "    unique_patients = list(set(patients))\n",
        "\n",
        "    # Number of folds\n",
        "    n_folds = 5\n",
        "\n",
        "    patients_per_fold = len(unique_patients)//n_folds\n",
        "    left = [(len(unique_patients)-i) for i in range(1, (len(unique_patients)%n_folds)+1)]\n",
        "\n",
        "    images_classes = dict(zip(images_names, classes))\n",
        "    assigned_patients = []\n",
        "    folds = []\n",
        "\n",
        "    for i in range(n_folds):\n",
        "\n",
        "        n_patients = 0\n",
        "\n",
        "        x = []\n",
        "        y = []\n",
        "\n",
        "        if i == n_folds-1:\n",
        "            for j in left:\n",
        "\n",
        "                patient = patients[-j]\n",
        "\n",
        "                imgs_patient = [name for name in image_names if patient in name]\n",
        "                x = x + imgs_patient\n",
        "                y = y + [images_classes[key] for key in imgs_patient]\n",
        "                n_patients += 1\n",
        "                assigned_patients.append(patient)\n",
        "\n",
        "        for k in range(len(unique_patients)):\n",
        "\n",
        "            patient = unique_patients[k]\n",
        "\n",
        "            if n_patients < patients_per_fold and patient not in assigned_patients:\n",
        "                imgs_patient = [name for name in image_names if patient in name]\n",
        "                x = x + imgs_patient\n",
        "                y = y + [images_classes[key] for key in imgs_patient]\n",
        "                n_patients += 1\n",
        "                assigned_patients.append(patient)\n",
        "\n",
        "        folds.append((x, y))\n",
        "\n",
        "    return folds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbQLaO1PoMcg",
      "metadata": {
        "id": "dbQLaO1PoMcg"
      },
      "outputs": [],
      "source": [
        "def preprocess(images_data):\n",
        "    \"\"\"\n",
        "    Apply normalization, blur and sharpening to the images\n",
        "\n",
        "    Params:\n",
        "    images_data: dictionary with images names as keys\n",
        "    and images as values\n",
        "\n",
        "    Return:\n",
        "    new_data: dictionary with images names as keys\n",
        "    and processed images as values\n",
        "    \"\"\"\n",
        "\n",
        "    new_data = images_data.copy()\n",
        "\n",
        "    for key, value in new_data.items():\n",
        "\n",
        "        img = value\n",
        "\n",
        "        # Normalize between 0 and 1\n",
        "        norm = cv.normalize(img, None, 0, 1.0, cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
        "\n",
        "        # Gaussian blur\n",
        "        blur = cv.GaussianBlur(norm, (3, 3), 1)\n",
        "\n",
        "        # Sharpen the image\n",
        "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "        sharp = cv.filter2D(blur, -1, kernel)\n",
        "\n",
        "        new_data[key] = sharp\n",
        "\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721",
      "metadata": {
        "id": "6ffde47d-d3b1-4b23-aa4a-624176aa0721"
      },
      "outputs": [],
      "source": [
        "def apply_thresholds(images_data):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "    images_data: dictionary with images names as keys\n",
        "    and images as values\n",
        "\n",
        "    Params:\n",
        "    imgs: list of raw images\n",
        "\n",
        "    Return:\n",
        "    new_data: dictionary with images names as keys\n",
        "    and (images, Otsu's, Adaptative) as values\n",
        "    extractor: pyradiomics extractor\n",
        "    \"\"\"\n",
        "\n",
        "    new_data = images_data.copy()\n",
        "\n",
        "    for key, value in new_data.items():\n",
        "\n",
        "        # Otsu's thresholding\n",
        "        _, th1 = cv.threshold(value, 100, 1, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "        # Adaptative gaussian thresholding\n",
        "        #th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n",
        "        th3 = cv.adaptiveThreshold(value, 1, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        new_data[key] = (value, th1, th3)\n",
        "\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d",
      "metadata": {
        "id": "0e1e017d-32d8-466e-8cb3-35b6a0ca267d"
      },
      "outputs": [],
      "source": [
        "# Cut images into 40x30\n",
        "images_data, patients, classes = cut_images(\"imagens_ihq_er\", 40, 30)\n",
        "\n",
        "# Divide images into folds\n",
        "images_names = list(images_data.keys())\n",
        "folds = divide_folds(images_names, patients, classes, 0.7)\n",
        "# Save folds variable\n",
        "# dump(folds, 'folds.joblib')\n",
        "\n",
        "# Preprocess images_data\n",
        "images_data = preprocess(images_data)\n",
        "# # Update images_data, applying Otsu's and adaptive thresholds\n",
        "images_data = apply_thresholds(images_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec",
      "metadata": {
        "id": "d2f16db1-548d-4e29-aadc-a7d72c4493ec"
      },
      "source": [
        "Extract features with PyRadiomics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45",
      "metadata": {
        "id": "1df52a57-9ed6-47f8-98ab-ad4a6c4c7a45"
      },
      "outputs": [],
      "source": [
        "def run_extractor(images_data, extractor):\n",
        "    \"\"\"\n",
        "    Extract features using sitk and pyradiomics\n",
        "\n",
        "    Params:\n",
        "    images_data: dictionary with images names as keys\n",
        "    and (images, Otsu's, Adaptative) as values\n",
        "    extractor: pyradiomics extractor\n",
        "\n",
        "    Returns:\n",
        "    features_otsu: features for otsu mask\n",
        "    features_adapt: features for adaptative mask\n",
        "    \"\"\"\n",
        "\n",
        "    data_spacing=[1,1,1]\n",
        "    features_otsu = {}\n",
        "    features_adapt = {}\n",
        "\n",
        "    for key, value in images_data.items():\n",
        "\n",
        "        # Get raw, Otsu's and adaptive images\n",
        "        img = value[0]\n",
        "        img_otsu = value[1]\n",
        "        img_adapt = value[2]\n",
        "\n",
        "        sitk_img = sitk.GetImageFromArray(img)\n",
        "        sitk_img.SetSpacing((1, 1, 1))\n",
        "        sitk_img = sitk.JoinSeries(sitk_img)\n",
        "\n",
        "        sitk_otsu = sitk.GetImageFromArray(img_otsu)\n",
        "        sitk_otsu.SetSpacing((1, 1, 1))\n",
        "        sitk_otsu = sitk.JoinSeries(sitk_otsu)\n",
        "        sitk_otsu = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        sitk_adapt = sitk.GetImageFromArray(img_adapt)\n",
        "        sitk_adapt.SetSpacing((1, 1, 1))\n",
        "        sitk_adapt = sitk.JoinSeries(sitk_adapt)\n",
        "        sitk_adapt = sitk.Cast(sitk_otsu, sitk.sitkInt32)\n",
        "\n",
        "        # Extract features and append them to the proper list\n",
        "        try:\n",
        "            ft_otsu = extractor.execute(sitk_img, sitk_otsu)\n",
        "            features_otsu[key] = ft_otsu\n",
        "\n",
        "            ft_adapt = extractor.execute(sitk_img, sitk_adapt)\n",
        "            features_adapt[key] = ft_adapt\n",
        "\n",
        "        except:\n",
        "            print(f\"{key}, \", end=\"\")\n",
        "            pass\n",
        "\n",
        "    return features_otsu, features_adapt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283f005e-92be-49b2-b869-f622389d0a68",
      "metadata": {
        "id": "283f005e-92be-49b2-b869-f622389d0a68"
      },
      "outputs": [],
      "source": [
        "def conditional_append(element, dest):\n",
        "    \"\"\"\n",
        "    Append element to the list destiny, if element is not in destiny\n",
        "\n",
        "    Params:\n",
        "    element: an element of any kind\n",
        "    dest: a destination list\n",
        "\n",
        "    Returns:\n",
        "    dest: list with appended element if the element was not in there\n",
        "    \"\"\"\n",
        "    if element not in dest:\n",
        "        dest.append(element)\n",
        "\n",
        "    return dest\n",
        "\n",
        "def process_features(feats_o, feats_a):\n",
        "    \"\"\"\n",
        "    Process features, in a way that:\n",
        "    - features that are dictionaries and strings are removed\n",
        "    - features that are tuples are separated and each element\n",
        "    of the tuple is considered one feature\n",
        "    - other types are converted to float\n",
        "\n",
        "    Params:\n",
        "    feats_o: list of Otsu's threshold features\n",
        "    feats_a: list of adaptativa threshold features\n",
        "\n",
        "    Returns:\n",
        "    all_feats_o: Otsu's features processed\n",
        "    all_feats_a: adaptative features processed\n",
        "    names = feature names processed\n",
        "    \"\"\"\n",
        "\n",
        "    all_feats_o = {}\n",
        "    all_feats_a = {}\n",
        "    names = []\n",
        "\n",
        "    # For each image in one of the features list\n",
        "    for key in feats_o:\n",
        "\n",
        "        # Get features for Otsu's and adaptive for this sample\n",
        "        sample_o = feats_o[key]\n",
        "        sample_a = feats_a[key]\n",
        "\n",
        "        values_o = []\n",
        "        values_a = []\n",
        "\n",
        "        # For each feature in the list\n",
        "        for ft in sample_o:\n",
        "\n",
        "            # Get the feature's value\n",
        "            value_o = sample_o[ft]\n",
        "            value_a = sample_a[ft]\n",
        "\n",
        "            # If the value is str or dict, ignore it\n",
        "            if type(value_o) == str or type(value_o) == dict:\n",
        "                continue\n",
        "            # If it's a tuple\n",
        "            elif type(value_o) == tuple:\n",
        "                for e in range(len(value_o)):\n",
        "                    # Add and index to the feature name\n",
        "                    conditional_append(f'{ft}_{e}', names)\n",
        "                    # Append float values to the lists\n",
        "                    values_o.append(float(value_o[e]))\n",
        "                    values_a.append(float(value_a[e]))\n",
        "            # For other data types, just append the name and float values\n",
        "            else:\n",
        "                conditional_append(ft, names)\n",
        "                values_o.append(float(value_o))\n",
        "                values_a.append(float(value_a))\n",
        "\n",
        "        # Append processed features to the general list\n",
        "        all_feats_o[key] = values_o\n",
        "        all_feats_a[key] = values_a\n",
        "\n",
        "    return all_feats_o, all_feats_a, names\n",
        "\n",
        "def extract_features(images_data):\n",
        "    \"\"\"\n",
        "    Process features, in a way that:\n",
        "    - features that are dictionaries and strings are removed\n",
        "    - features that are tuples are separated and each element\n",
        "    of the tuple is considered one feature\n",
        "    - other types are converted to float\n",
        "    Get the features' names, with tuple features indexed\n",
        "\n",
        "    Params:\n",
        "    images_data: dictionary with images names as keys\n",
        "    and (images, Otsu's, Adaptative) as values\n",
        "\n",
        "    Returns:\n",
        "    all_folds_feats: dictionary containing Otsu's features\n",
        "    and adaptive features for each fold\n",
        "    names: feature names\n",
        "    \"\"\"\n",
        "\n",
        "    # Create feature extractor\n",
        "    !wget -c https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
        "    params = 'Params.yaml'\n",
        "    settings = {'label': 1, 'correctMask': True}\n",
        "    extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True, **settings)\n",
        "\n",
        "    # Extract features from Otsu's and adaptative\n",
        "    feats_o, feats_a = run_extractor(images_data, extractor)\n",
        "\n",
        "    # Process features and get feature names\n",
        "    all_feats_o, all_feats_a, names = process_features(feats_o, feats_a)\n",
        "\n",
        "    return all_feats_o, all_feats_a, names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e61d82-9315-4171-93fd-1bdbe27b17bf",
      "metadata": {
        "id": "b0e61d82-9315-4171-93fd-1bdbe27b17bf"
      },
      "outputs": [],
      "source": [
        "# Division of images_data dictionary in 4 parts\n",
        "# to extract features easily\n",
        "\n",
        "# lista = list(images_data.keys())\n",
        "# p = lista[:10000]\n",
        "# s = lista[10000:20000]\n",
        "# t = lista[20000:30000]\n",
        "# q = lista[30000:40000]\n",
        "\n",
        "# pp = {k:images_data[k] for k in p}\n",
        "# ss = {k:images_data[k] for k in s}\n",
        "# tt = {k:images_data[k] for k in t}\n",
        "# qq = {k:images_data[k] for k in q}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c20992f0-183f-4cff-b718-67608f9100ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c20992f0-183f-4cff-b718-67608f9100ff",
        "outputId": "d35978d6-b274-4a7a-f90f-7f88fa7a49cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-26 23:10:38--  https://raw.githubusercontent.com/AIM-Harvard/pyradiomics/master/examples/exampleSettings/Params.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:radiomics.featureextractor:Loading parameter file Params.yaml\n",
            "INFO:radiomics.featureextractor:Applying custom setting overrides: {'additionalInfo': True, 'label': 1, 'correctMask': True}\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.featureextractor:Computing firstorder\n",
            "INFO:radiomics.featureextractor:Computing glcm\n",
            "INFO:radiomics.featureextractor:Computing glrlm\n",
            "INFO:radiomics.featureextractor:Computing glszm\n",
            "INFO:radiomics.featureextractor:Computing gldm\n"
          ]
        }
      ],
      "source": [
        "# Extract all features\n",
        "all_feats_o, all_feats_a, ft_names = extract_features(images_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I3VzTAqtkwpw",
      "metadata": {
        "id": "I3VzTAqtkwpw"
      },
      "outputs": [],
      "source": [
        "def save_features(all_feats_o, all_feats_a):\n",
        "    \"\"\"\n",
        "    Save features of all images in .txt files\n",
        "\n",
        "    Params:\n",
        "    all_feats_o:\n",
        "\n",
        "    Returns:\n",
        "    all_folds_feats = dictionary containing Otsu's features\n",
        "    and adaptive features for each fold\n",
        "    names = feature names\n",
        "    \"\"\"\n",
        "\n",
        "    out_o = 'features_o/'\n",
        "    out_a = 'features_a/'\n",
        "\n",
        "    os.makedirs(out_o, exist_ok=True)\n",
        "    os.makedirs(out_a, exist_ok=True)\n",
        "\n",
        "    for key in all_feats_o:\n",
        "\n",
        "        ft_o = all_feats_o[key]\n",
        "        ft_a = all_feats_a[key]\n",
        "\n",
        "        filename_o = f'{key}_o.txt'\n",
        "        filename_a = f'{key}_a.txt'\n",
        "\n",
        "        with open(os.path.join(out_o, filename_o), 'w') as f:\n",
        "            for elem in ft_o:\n",
        "                f.write(f'{elem}\\n')\n",
        "\n",
        "        with open(os.path.join(out_a, filename_a), 'w') as f:\n",
        "            for elem in ft_a:\n",
        "                f.write(f'{elem}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2tsatBXxmRjl",
      "metadata": {
        "id": "2tsatBXxmRjl"
      },
      "outputs": [],
      "source": [
        "# Save features and feature_names\n",
        "save_features(all_feats_o, all_feats_a)\n",
        "with open('ft_names.txt', 'w') as f:\n",
        "    f.write('\\n'.join(ft_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a40d964-b6dd-4b05-9c09-4bf3332f5925",
      "metadata": {
        "id": "8a40d964-b6dd-4b05-9c09-4bf3332f5925"
      },
      "outputs": [],
      "source": [
        "# Download features\n",
        "!zip -r /content/features_o.zip /content/features_o\n",
        "!zip -r /content/features_a.zip /content/features_a\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/features_o.zip\")\n",
        "files.download(\"/content/features_a.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ab78d6-0286-4068-ad79-297575b553a1",
      "metadata": {
        "id": "26ab78d6-0286-4068-ad79-297575b553a1"
      },
      "source": [
        "Read features and folds and prepare for training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0df21bbe-f7d8-4f36-9f69-71051b6a221f",
      "metadata": {
        "id": "0df21bbe-f7d8-4f36-9f69-71051b6a221f"
      },
      "outputs": [],
      "source": [
        "def read_files(ft_names_path, folds_path):\n",
        "    \"\"\"\n",
        "    Read feature names and fold files\n",
        "\n",
        "    Params:\n",
        "    ft_names_path: path to the feature names .txt file\n",
        "    folds_path: path to the folds .joblib file\n",
        "\n",
        "    Returns:\n",
        "    ft_names: list of radiomics feature names\n",
        "    folds: list of tuples, each tuple is one fold containing (imgs_names, labels)\n",
        "    \"\"\"\n",
        "\n",
        "    ft_names = []\n",
        "\n",
        "    # Open file and read the content in a list\n",
        "    with open(ft_names_path, 'r') as f:\n",
        "        for line in f:\n",
        "\n",
        "            # Remove linebreak\n",
        "            x = line[:-1]\n",
        "\n",
        "            # Add feature name to the list\n",
        "            ft_names.append(str(x))\n",
        "\n",
        "    # Load folds\n",
        "    folds = load(folds_path)\n",
        "\n",
        "    return ft_names, folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "iMaTEgPnmeca",
      "metadata": {
        "id": "iMaTEgPnmeca"
      },
      "outputs": [],
      "source": [
        "def read_features(ft_path, fold_images, label):\n",
        "    \"\"\"\n",
        "    Read features from files\n",
        "\n",
        "    Params:\n",
        "    ft_path: path to the feature names .txt file\n",
        "    fold_images: list of image names for a fold\n",
        "    label\n",
        "\n",
        "    Returns:\n",
        "    features: list of features\n",
        "    names: list of names\n",
        "    labels: list of labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to return\n",
        "    features = []\n",
        "    names = []\n",
        "    labels = []\n",
        "\n",
        "    # For feature file in the path\n",
        "    for ft_file in os.listdir(ft_path):\n",
        "\n",
        "        # List of features for this image\n",
        "        ft_o = []\n",
        "\n",
        "        # Get patient name from the file\n",
        "        patient = ft_file.split(\"-\")[0]\n",
        "\n",
        "        # Look for the patient in the fold images_names\n",
        "        for k, image_name in enumerate(fold_images):\n",
        "            if patient in image_name:\n",
        "                # Try to open file and read the content to a list\n",
        "                try:\n",
        "                    #print(f'achei o {patient} no fold')\n",
        "                    with open(os.path.join(ft_path, ft_file), 'r') as f:\n",
        "                        for line in f:\n",
        "\n",
        "                            # Remove linebreak\n",
        "                            x = line[:-1]\n",
        "\n",
        "                            # Add current feature to the list\n",
        "                            ft_o.append(float(x))\n",
        "\n",
        "                    names.append(image_name)\n",
        "                    labels.append(label[k])\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                # Break if patient found\n",
        "                break\n",
        "\n",
        "        if len(ft_o) != 0:\n",
        "            features.append(ft_o)\n",
        "\n",
        "    return features, names, labels\n",
        "\n",
        "def create_dfs(path_o, path_a, fold, ft_names):\n",
        "    \"\"\"\n",
        "    Create dataframes for the data\n",
        "\n",
        "    Params:\n",
        "    fold: tuple of (imgs_names, labels)\n",
        "\n",
        "    Returns:\n",
        "    ft_names: list of radiomics feature names\n",
        "    folds: list of tuples, each tuple is one fold containing (imgs, labels)\n",
        "    \"\"\"\n",
        "\n",
        "    x = fold[0]\n",
        "    y = fold[1]\n",
        "\n",
        "    # Dataframe for Otsu's features\n",
        "    ft_o, index_o, label_o = read_features(path_o, x, y)\n",
        "    df_o = pd.DataFrame(ft_o, columns = ft_names, index = index_o)\n",
        "    df_o.insert(loc=1, column='label', value=label_o)\n",
        "\n",
        "    # Dataframe for adaptive features\n",
        "    ft_a, index_a, label_a = read_features(path_a, x, y)\n",
        "    df_a = pd.DataFrame(ft_a, columns = ft_names, index = index_a)\n",
        "    df_a.insert(loc=1, column='label', value=label_a)\n",
        "\n",
        "    return df_o, df_a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "6cDUpYSoN2Jm",
      "metadata": {
        "id": "6cDUpYSoN2Jm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "wget -q https://github.com/vitoriastavis/ufpr-medical-images/raw/main/features_o.tar.gz\n",
        "wget -q https://github.com/vitoriastavis/ufpr-medical-images/raw/main/features_a.tar.gz\n",
        "wget -q https://github.com/vitoriastavis/ufpr-medical-images/raw/main/features_ap.tar.gz\n",
        "wget -q https://github.com/vitoriastavis/ufpr-medical-images/raw/main/features_op.tar.gz\n",
        "wget -q https://github.com/vitoriastavis/ufpr-medical-images/raw/main/folds.tar.gz\n",
        "wget -q https://raw.githubusercontent.com/vitoriastavis/ufpr-medical-images/main/ft_names.txt\n",
        "\n",
        "tar -xf features_o.tar.gz\n",
        "tar -xf features_a.tar.gz\n",
        "tar -xf features_op.tar.gz\n",
        "tar -xf features_ap.tar.gz\n",
        "tar -xf folds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The variable 'folds' is a list of tuples\n",
        "# folds[0] is the first fold\n",
        "# in each fold, there are (image_names, labels)\n",
        "# which are used to build the dataframes below\n",
        "# also using ft_names, which are names of the features to use as column names\n",
        "ft_names, folds = read_files('ft_names.txt', 'folds.joblib')"
      ],
      "metadata": {
        "id": "QvLBcPgGaTRk"
      },
      "id": "QvLBcPgGaTRk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dfs for non processed images\n",
        "dataframes_np = []\n",
        "for i in range(len(folds)):\n",
        "  df_o, df_a = create_dfs(False, folds[i], ft_names)\n",
        "  dataframes_np.append((df_o, df_a))\n",
        "\n",
        "# Create dfs for processed images\n",
        "dataframes_p = []\n",
        "for i in range(len(folds)):\n",
        "  df_o, df_a = create_dfs(True, folds[i], ft_names)\n",
        "  dataframes_p.append((df_o, df_a))"
      ],
      "metadata": {
        "id": "EEGjbkmHJjip"
      },
      "id": "EEGjbkmHJjip",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "bcb79fd6-1b6d-457a-9ce8-9ce18b20de12",
      "metadata": {
        "id": "bcb79fd6-1b6d-457a-9ce8-9ce18b20de12"
      },
      "outputs": [],
      "source": [
        "def classifier(method, dataframes=None, threshold='', verbose=True):\n",
        "    \"\"\"\n",
        "    classify features using knn\n",
        "\n",
        "    Params:\n",
        "    threshold: name of threshold filter\n",
        "    data: optional dictionary data\n",
        "\n",
        "    Returns:\n",
        "    f1_list: list of f1 scores to create a dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    f1_list = []\n",
        "\n",
        "    ans = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1_score\": []}\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Classifying with {method} - {threshold} \\n')\n",
        "\n",
        "    # 5-fold cross validation\n",
        "    for i in range(len(dataframes)):\n",
        "        # Create dataframe from current folder\n",
        "        (df_o, df_a) = dataframes[i]\n",
        "        if (threshold == 'otsu'):\n",
        "            df = df_o\n",
        "        elif (threshold == 'adaptive'):\n",
        "            df = df_a\n",
        "\n",
        "        # Predictor variables\n",
        "        X = df.drop(['label'], axis=1).values\n",
        "\n",
        "        # Target variables\n",
        "        y = df['label'].values\n",
        "\n",
        "        # Creates classifier with selected parameters\n",
        "        if method == 'knn':\n",
        "          clf = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
        "        elif method == 'mlp':\n",
        "          clf = MLPClassifier(max_iter=300, activation='logistic', solver='adam')\n",
        "        else:\n",
        "          print('invalid method, try knn or mlp')\n",
        "          exit()\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "        # Standardize features by removing the mean and scaling to unit variance\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Fit the model\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Get the score\n",
        "        score = clf.score(X_test, y_test)\n",
        "\n",
        "        # Predicting\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Creates confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        if verbose:\n",
        "          print(f'\\t\\t {method} - Fold {i+1} | threshold {threshold}')\n",
        "          print (f'Confusion Matrix \\n {cm}')\n",
        "          print(classification_report(y_test, y_pred))\n",
        "          print()\n",
        "\n",
        "        # Get classification report\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        precision = report['macro avg']['precision']\n",
        "        recall = report['macro avg']['recall']\n",
        "        f1 = report['macro avg']['f1-score']\n",
        "\n",
        "        # List of metrics\n",
        "        ans[\"accuracy\"].append(round(score, 3))\n",
        "        ans[\"precision\"].append(round(precision, 3))\n",
        "        ans[\"recall\"].append(round(recall), 3)\n",
        "        ans[\"f1_score\"].append(round(f1), 3)\n",
        "\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    # Print the results\n",
        "    results = {\"accuracy\": round(np.mean(ans[\"accuracy\"]), 3),\n",
        "               \"precision\": round(np.mean(ans[\"precision\"]), 3),\n",
        "               \"recall\": round(np.mean(ans[\"recall\"]), 3),\n",
        "               \"f1_score\": round(np.mean(ans[\"f1_score\"]), 3)}\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Classification done! Average metrics:\")\n",
        "      print(results)\n",
        "      print()\n",
        "\n",
        "    return f1_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_knn_otsu_np = classifier('knn', dataframes_np, 'otsu')\n",
        "f1_knn_adapt_np = classifier('knn', dataframes_np, 'adaptive')\n",
        "f1_mlp_otsu_np = classifier('mlp', dataframes_np, 'otsu')\n",
        "f1_mlp_adapt_np = classifier('mlp', dataframes_np, 'adaptive')"
      ],
      "metadata": {
        "id": "dzhzLYiBYMVJ"
      },
      "id": "dzhzLYiBYMVJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header = ['Otsu (NP)', 'Adaptive (NP)']"
      ],
      "metadata": {
        "id": "0oZAadPpNfgg"
      },
      "id": "0oZAadPpNfgg",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_np_knn = pd.DataFrame(np.transpose([f1_knn_otsu_np, f1_knn_adapt_np]), columns = header)\n",
        "results_np_knn.index = [i+1 for i in results_np_knn.index]\n",
        "results_np_knn.index.name = 'Fold'"
      ],
      "metadata": {
        "id": "giumblorUnpy"
      },
      "id": "giumblorUnpy",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_np_mlp = pd.DataFrame(np.transpose([f1_mlp_otsu_np, f1_mlp_adapt_np]), columns = header)\n",
        "results_np_mlp.index = [i+1 for i in results_np_mlp.index]\n",
        "results_np_mlp.index.name = 'Fold'"
      ],
      "metadata": {
        "id": "D22NJDHdV5fG"
      },
      "id": "D22NJDHdV5fG",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_knn_otsu_p = classifier('knn', dataframes_p, 'otsu')\n",
        "f1_knn_adapt_p = classifier('knn', dataframes_p, 'adaptive')\n",
        "f1_mlp_otsu_p = classifier('mlp', dataframes_p, 'otsu')\n",
        "f1_mlp_adapt_p = classifier('mlp', dataframes_p, 'adaptive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_dGcgtWPze",
        "outputId": "2f3d8088-27a2-48de-f8bb-9799b4d7886d"
      },
      "id": "NW_dGcgtWPze",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying with knn - otsu \n",
            "\n",
            "\t\t knn - Fold 1 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[174  53   3  10]\n",
            " [ 66 360  16  26]\n",
            " [  8  32 267  88]\n",
            " [ 33  96 148 411]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.72      0.67       240\n",
            "           1       0.67      0.77      0.71       468\n",
            "           2       0.62      0.68      0.64       395\n",
            "           3       0.77      0.60      0.67       688\n",
            "\n",
            "    accuracy                           0.68      1791\n",
            "   macro avg       0.67      0.69      0.67      1791\n",
            "weighted avg       0.69      0.68      0.68      1791\n",
            "\n",
            "\n",
            "\t\t knn - Fold 2 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[143   7  19  19]\n",
            " [  5 214  17  66]\n",
            " [ 15  25 106  30]\n",
            " [ 30 103  36 558]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.76      0.75       188\n",
            "           1       0.61      0.71      0.66       302\n",
            "           2       0.60      0.60      0.60       176\n",
            "           3       0.83      0.77      0.80       727\n",
            "\n",
            "    accuracy                           0.73      1393\n",
            "   macro avg       0.69      0.71      0.70      1393\n",
            "weighted avg       0.74      0.73      0.74      1393\n",
            "\n",
            "\n",
            "\t\t knn - Fold 3 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[540 115  28  21]\n",
            " [151 332  23  14]\n",
            " [ 98  69  80  36]\n",
            " [ 68  40  14 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.77      0.69       704\n",
            "           1       0.60      0.64      0.62       520\n",
            "           2       0.55      0.28      0.37       283\n",
            "           3       0.74      0.62      0.68       325\n",
            "\n",
            "    accuracy                           0.63      1832\n",
            "   macro avg       0.63      0.58      0.59      1832\n",
            "weighted avg       0.63      0.63      0.62      1832\n",
            "\n",
            "\n",
            "\t\t knn - Fold 4 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[636   4  49]\n",
            " [ 61  11   8]\n",
            " [146   7 397]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.92      0.83       689\n",
            "           2       0.50      0.14      0.22        80\n",
            "           3       0.87      0.72      0.79       550\n",
            "\n",
            "    accuracy                           0.79      1319\n",
            "   macro avg       0.71      0.59      0.61      1319\n",
            "weighted avg       0.79      0.79      0.78      1319\n",
            "\n",
            "\n",
            "\t\t knn - Fold 5 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[363  12  94  30]\n",
            " [ 73  25  23   6]\n",
            " [109  15 353  25]\n",
            " [ 87   1  78 142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.73      0.64       499\n",
            "           1       0.47      0.20      0.28       127\n",
            "           2       0.64      0.70      0.67       502\n",
            "           3       0.70      0.46      0.56       308\n",
            "\n",
            "    accuracy                           0.61      1436\n",
            "   macro avg       0.60      0.52      0.54      1436\n",
            "weighted avg       0.62      0.61      0.60      1436\n",
            "\n",
            "\n",
            "Classification done!\n",
            "{'accuracy': 0.69, 'precision': 0.66, 'recall': 0.62, 'f1_score': 0.62}\n",
            "Classifying with knn - adaptive \n",
            "\n",
            "\t\t knn - Fold 1 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[156  63   1  19]\n",
            " [ 64 364   9  39]\n",
            " [  5  19 301 107]\n",
            " [ 29  83 131 401]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.65      0.63       239\n",
            "           1       0.69      0.76      0.72       476\n",
            "           2       0.68      0.70      0.69       432\n",
            "           3       0.71      0.62      0.66       644\n",
            "\n",
            "    accuracy                           0.68      1791\n",
            "   macro avg       0.67      0.68      0.68      1791\n",
            "weighted avg       0.68      0.68      0.68      1791\n",
            "\n",
            "\n",
            "\t\t knn - Fold 2 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[155   7   9  20]\n",
            " [  2 218  22  51]\n",
            " [ 16  33 107  28]\n",
            " [ 28  97  45 555]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79       191\n",
            "           1       0.61      0.74      0.67       293\n",
            "           2       0.58      0.58      0.58       184\n",
            "           3       0.85      0.77      0.80       725\n",
            "\n",
            "    accuracy                           0.74      1393\n",
            "   macro avg       0.70      0.73      0.71      1393\n",
            "weighted avg       0.75      0.74      0.75      1393\n",
            "\n",
            "\n",
            "\t\t knn - Fold 3 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[525 121  38  36]\n",
            " [149 345  18  15]\n",
            " [109  56  67  37]\n",
            " [ 63  27  19 207]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.73      0.67       720\n",
            "           1       0.63      0.65      0.64       527\n",
            "           2       0.47      0.25      0.33       269\n",
            "           3       0.70      0.66      0.68       316\n",
            "\n",
            "    accuracy                           0.62      1832\n",
            "   macro avg       0.61      0.57      0.58      1832\n",
            "weighted avg       0.61      0.62      0.61      1832\n",
            "\n",
            "\n",
            "\t\t knn - Fold 4 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[644   9  58]\n",
            " [ 77   7  10]\n",
            " [143   3 368]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.91      0.82       711\n",
            "           2       0.37      0.07      0.12        94\n",
            "           3       0.84      0.72      0.77       514\n",
            "\n",
            "    accuracy                           0.77      1319\n",
            "   macro avg       0.65      0.57      0.57      1319\n",
            "weighted avg       0.76      0.77      0.75      1319\n",
            "\n",
            "\n",
            "\t\t knn - Fold 5 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[367  20  83  32]\n",
            " [ 81  25  22  11]\n",
            " [126  14 348  23]\n",
            " [ 79   6  60 139]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.73      0.64       502\n",
            "           1       0.38      0.18      0.25       139\n",
            "           2       0.68      0.68      0.68       511\n",
            "           3       0.68      0.49      0.57       284\n",
            "\n",
            "    accuracy                           0.61      1436\n",
            "   macro avg       0.58      0.52      0.53      1436\n",
            "weighted avg       0.61      0.61      0.60      1436\n",
            "\n",
            "\n",
            "Classification done!\n",
            "{'accuracy': 0.69, 'precision': 0.64, 'recall': 0.61, 'f1_score': 0.61}\n",
            "Classifying with mlp - otsu \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 1 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[162  53   0  16]\n",
            " [ 43 422  18  45]\n",
            " [  2  25 264  95]\n",
            " [ 25  77  82 462]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       231\n",
            "           1       0.73      0.80      0.76       528\n",
            "           2       0.73      0.68      0.70       386\n",
            "           3       0.75      0.72      0.73       646\n",
            "\n",
            "    accuracy                           0.73      1791\n",
            "   macro avg       0.73      0.72      0.72      1791\n",
            "weighted avg       0.73      0.73      0.73      1791\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 2 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[146   2   7  22]\n",
            " [  3 236  23  58]\n",
            " [  6  13 115  34]\n",
            " [ 13  56  24 635]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.85       177\n",
            "           1       0.77      0.74      0.75       320\n",
            "           2       0.68      0.68      0.68       168\n",
            "           3       0.85      0.87      0.86       728\n",
            "\n",
            "    accuracy                           0.81      1393\n",
            "   macro avg       0.79      0.78      0.79      1393\n",
            "weighted avg       0.81      0.81      0.81      1393\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 3 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[521 117  44  30]\n",
            " [ 88 408  15  17]\n",
            " [ 59  39 112  34]\n",
            " [ 47  34  18 249]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73       712\n",
            "           1       0.68      0.77      0.72       528\n",
            "           2       0.59      0.46      0.52       244\n",
            "           3       0.75      0.72      0.73       348\n",
            "\n",
            "    accuracy                           0.70      1832\n",
            "   macro avg       0.69      0.67      0.68      1832\n",
            "weighted avg       0.70      0.70      0.70      1832\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 4 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[602  12 103]\n",
            " [ 47  23  10]\n",
            " [ 94   9 419]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.82       717\n",
            "           2       0.52      0.29      0.37        80\n",
            "           3       0.79      0.80      0.80       522\n",
            "\n",
            "    accuracy                           0.79      1319\n",
            "   macro avg       0.71      0.64      0.66      1319\n",
            "weighted avg       0.78      0.79      0.79      1319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 5 | threshold otsu\n",
            "Confusion Matrix \n",
            " [[379  19  72  37]\n",
            " [ 48  54  17  17]\n",
            " [ 79  13 402  39]\n",
            " [ 45   9  50 156]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72       507\n",
            "           1       0.57      0.40      0.47       136\n",
            "           2       0.74      0.75      0.75       533\n",
            "           3       0.63      0.60      0.61       260\n",
            "\n",
            "    accuracy                           0.69      1436\n",
            "   macro avg       0.66      0.62      0.64      1436\n",
            "weighted avg       0.69      0.69      0.69      1436\n",
            "\n",
            "\n",
            "Classification done!\n",
            "{'accuracy': 0.75, 'precision': 0.71, 'recall': 0.69, 'f1_score': 0.7}\n",
            "Classifying with mlp - adaptive \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 1 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[164  55   3  18]\n",
            " [ 49 403  17  54]\n",
            " [  0  15 271  94]\n",
            " [ 14  69  89 476]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70       240\n",
            "           1       0.74      0.77      0.76       523\n",
            "           2       0.71      0.71      0.71       380\n",
            "           3       0.74      0.73      0.74       648\n",
            "\n",
            "    accuracy                           0.73      1791\n",
            "   macro avg       0.73      0.73      0.73      1791\n",
            "weighted avg       0.73      0.73      0.73      1791\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 2 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[132   3   7  19]\n",
            " [  1 233  18  45]\n",
            " [  2  24 122  30]\n",
            " [ 15  59  31 652]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.82      0.85       161\n",
            "           1       0.73      0.78      0.76       297\n",
            "           2       0.69      0.69      0.69       178\n",
            "           3       0.87      0.86      0.87       757\n",
            "\n",
            "    accuracy                           0.82      1393\n",
            "   macro avg       0.79      0.79      0.79      1393\n",
            "weighted avg       0.82      0.82      0.82      1393\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 3 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[522 114  52  26]\n",
            " [ 94 378  24  26]\n",
            " [ 57  31 107  51]\n",
            " [ 44  16  40 250]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73       714\n",
            "           1       0.70      0.72      0.71       522\n",
            "           2       0.48      0.43      0.46       246\n",
            "           3       0.71      0.71      0.71       350\n",
            "\n",
            "    accuracy                           0.69      1832\n",
            "   macro avg       0.65      0.65      0.65      1832\n",
            "weighted avg       0.68      0.69      0.68      1832\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t mlp - Fold 4 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[591  12 102]\n",
            " [ 45  26  18]\n",
            " [ 99   7 419]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       705\n",
            "           2       0.58      0.29      0.39        89\n",
            "           3       0.78      0.80      0.79       525\n",
            "\n",
            "    accuracy                           0.79      1319\n",
            "   macro avg       0.72      0.64      0.67      1319\n",
            "weighted avg       0.78      0.79      0.78      1319\n",
            "\n",
            "\n",
            "\t\t mlp - Fold 5 | threshold adaptive\n",
            "Confusion Matrix \n",
            " [[379  35  62  23]\n",
            " [ 39  56  25  14]\n",
            " [ 62  12 389  42]\n",
            " [ 54  13  59 172]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.76      0.73       499\n",
            "           1       0.48      0.42      0.45       134\n",
            "           2       0.73      0.77      0.75       505\n",
            "           3       0.69      0.58      0.63       298\n",
            "\n",
            "    accuracy                           0.69      1436\n",
            "   macro avg       0.65      0.63      0.64      1436\n",
            "weighted avg       0.69      0.69      0.69      1436\n",
            "\n",
            "\n",
            "Classification done!\n",
            "{'accuracy': 0.74, 'precision': 0.71, 'recall': 0.69, 'f1_score': 0.69}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_p_knn = pd.DataFrame(np.transpose([f1_knn_otsu_p, f1_knn_adapt_p]), columns = header)\n",
        "results_p_knn.index = [i+1 for i in results_p_knn.index]\n",
        "results_p_knn.index.name = 'Fold'"
      ],
      "metadata": {
        "id": "XOY4bmAxYf-D"
      },
      "id": "XOY4bmAxYf-D",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_p_mlp = pd.DataFrame(np.transpose([f1_mlp_otsu_p, f1_mlp_adapt_p]), columns = header)\n",
        "results_p_mlp.index = [i+1 for i in results_p_mlp.index]\n",
        "results_p_mlp.index.name = 'Fold'"
      ],
      "metadata": {
        "id": "jsQ1D5kcYjc5"
      },
      "id": "jsQ1D5kcYjc5",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "levels = ['Not preprocessed', 'Preprocessed']"
      ],
      "metadata": {
        "id": "_wL3ZRDgYjPx"
      },
      "id": "_wL3ZRDgYjPx",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_knn = pd.concat([results_np_knn, results_p_knn], axis=1, keys =levels)"
      ],
      "metadata": {
        "id": "N2JmTvSGYyOL"
      },
      "id": "N2JmTvSGYyOL",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_knn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "6pzoVZuyb7u9",
        "outputId": "94702ee4-71a9-4330-c530-eb6cd55582d6"
      },
      "id": "6pzoVZuyb7u9",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Not preprocessed               Preprocessed              \n",
              "            Otsu (NP) Adaptive (NP)    Otsu (NP) Adaptive (NP)\n",
              "Fold                                                          \n",
              "1            0.674490      0.668885     0.674448      0.677209\n",
              "2            0.704497      0.702514     0.701030      0.712923\n",
              "3            0.569883      0.562232     0.590148      0.578843\n",
              "4            0.602405      0.558448     0.612270      0.572136\n",
              "5            0.528268      0.524298     0.536960      0.532198"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71c59691-66cb-4907-9d83-6cb80a7fa271\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Not preprocessed</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Preprocessed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Otsu (NP)</th>\n",
              "      <th>Adaptive (NP)</th>\n",
              "      <th>Otsu (NP)</th>\n",
              "      <th>Adaptive (NP)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fold</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674490</td>\n",
              "      <td>0.668885</td>\n",
              "      <td>0.674448</td>\n",
              "      <td>0.677209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.704497</td>\n",
              "      <td>0.702514</td>\n",
              "      <td>0.701030</td>\n",
              "      <td>0.712923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.569883</td>\n",
              "      <td>0.562232</td>\n",
              "      <td>0.590148</td>\n",
              "      <td>0.578843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.602405</td>\n",
              "      <td>0.558448</td>\n",
              "      <td>0.612270</td>\n",
              "      <td>0.572136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.528268</td>\n",
              "      <td>0.524298</td>\n",
              "      <td>0.536960</td>\n",
              "      <td>0.532198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c59691-66cb-4907-9d83-6cb80a7fa271')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71c59691-66cb-4907-9d83-6cb80a7fa271 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71c59691-66cb-4907-9d83-6cb80a7fa271');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e750dc02-7d13-44c6-a997-b952822df06e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e750dc02-7d13-44c6-a997-b952822df06e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e750dc02-7d13-44c6-a997-b952822df06e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_mlp = pd.concat([results_np_mlp, results_p_mlp], axis=1, keys=levels)"
      ],
      "metadata": {
        "id": "MOvXGqi9cRWw"
      },
      "id": "MOvXGqi9cRWw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # Check if at least one argument is provided\n",
        "    if len(sys.argv) < 3 or len(sys.argv) > 4:\n",
        "        print(\"Usage: python classification.py path_o path_a \\n Options: -v\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    elif (len(sys.argv)) == 3:\n",
        "        path_o = sys.argv[1]\n",
        "        path_a = sys.argv[2]\n",
        "        verbose = False\n",
        "\n",
        "    elif (len(sys.argv)) == 4 and sys.argv[1] == '-v':\n",
        "        path_o = sys.argv[2]\n",
        "        path_a = sys.argv[3]\n",
        "        verbose = True\n",
        "\n",
        "\n",
        "    # The variable 'folds' is a list of tuples\n",
        "    # folds[0] is the first fold\n",
        "    # in each fold, there are (image_names, labels)\n",
        "    # which are used to build the dataframes below\n",
        "    # also using ft_names, which are names of the features to use as column names\n",
        "    ft_names, folds = read_files('ft_names.txt', 'folds.joblib')\n",
        "\n",
        "    # Create dfs for non processed images\n",
        "    dataframes_np = []\n",
        "    for i in range(len(folds)):\n",
        "      df_o, df_a = create_dfs(sys.argv[1], folds[i], ft_names)\n",
        "      dataframes_np.append((df_o, df_a))\n",
        "\n",
        "    # Create dfs for processed images\n",
        "    dataframes_p = []\n",
        "    for i in range(len(folds)):\n",
        "      df_o, df_a = create_dfs(sys.argv[2], folds[i], ft_names)\n",
        "      dataframes_p.append((df_o, df_a))\n",
        "\n",
        "    # Classification for non processed images\n",
        "    f1_knn_otsu_np = classifier('knn', dataframes_np, 'otsu', verbose)\n",
        "    f1_knn_adapt_np = classifier('knn', dataframes_np, 'adaptive', verbose)\n",
        "    f1_mlp_otsu_np = classifier('mlp', dataframes_np, 'otsu', verbose)\n",
        "    f1_mlp_adapt_np = classifier('mlp', dataframes_np, 'adaptive', verbose)\n",
        "\n",
        "    # Classification for processed images\n",
        "    f1_knn_otsu_p = classifier('knn', dataframes_p, 'otsu', verbose)\n",
        "    f1_knn_adapt_p = classifier('knn', dataframes_p, 'adaptive', verbose)\n",
        "    f1_mlp_otsu_p = classifier('mlp', dataframes_p, 'otsu', verbose)\n",
        "    f1_mlp_adapt_p = classifier('mlp', dataframes_p, 'adaptive', verbose)\n",
        "\n",
        "    header = ['Otsu (NP)', 'Adaptive (NP)']\n",
        "    levels = ['Not preprocessed', 'Preprocessed']\n",
        "\n",
        "    # Result dataframes\n",
        "    results_np_knn = pd.DataFrame(np.transpose([f1_knn_otsu_np, f1_knn_adapt_np]), columns = header)\n",
        "    results_np_mlp = pd.DataFrame(np.transpose([f1_mlp_otsu_np, f1_mlp_adapt_np]), columns = header)\n",
        "\n",
        "    results_p_knn = pd.DataFrame(np.transpose([f1_knn_otsu_p, f1_knn_adapt_p]), columns = header)\n",
        "    results_p_mlp = pd.DataFrame(np.transpose([f1_mlp_otsu_p, f1_mlp_adapt_p]), columns = header)\n",
        "\n",
        "    results_knn = pd.concat([results_np_knn, results_p_knn], axis=1, keys =levels)\n",
        "    results_mlp = pd.concat([results_np_mlp, results_p_mlp], axis=1, keys=levels)\n",
        "\n",
        "    results_knn.index = [i+1 for i in results_knn.index]\n",
        "    results_knn.index.name = 'Fold'\n",
        "\n",
        "    results_mlp.index = [i+1 for i in results_mlp.index]\n",
        "    results_mlp.index.name = 'Fold'\n",
        "\n",
        "    print('Final dataframes: KNN - F1-score')\n",
        "    print(results_knn)\n",
        "\n",
        "    print('Final dataframes: MLP - F1-score')\n",
        "    print(results_knn)"
      ],
      "metadata": {
        "id": "RgxJdRQ-ZkDa"
      },
      "id": "RgxJdRQ-ZkDa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}